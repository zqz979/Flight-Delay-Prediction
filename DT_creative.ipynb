{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARR_DEL15</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>DOW</th>\n",
       "      <th>AIR_STOCK</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>...</th>\n",
       "      <th>ORIGIN_CITY_MARKET_ID</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>ORIGIN_STATE_FIPS</th>\n",
       "      <th>ORIGIN_WAC</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEST_CITY_MARKET_ID</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEST_STATE_FIPS</th>\n",
       "      <th>DEST_WAC</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>6847.589844</td>\n",
       "      <td>570.89</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>6847.589844</td>\n",
       "      <td>570.89</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>275.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>6847.589844</td>\n",
       "      <td>570.89</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>6847.589844</td>\n",
       "      <td>570.89</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1038.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>6847.589844</td>\n",
       "      <td>570.89</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345612</th>\n",
       "      <td>1.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>15741.559570</td>\n",
       "      <td>465.45</td>\n",
       "      <td>42.720001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5863.0</td>\n",
       "      <td>...</td>\n",
       "      <td>187.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345613</th>\n",
       "      <td>1.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>15741.559570</td>\n",
       "      <td>465.45</td>\n",
       "      <td>42.720001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5863.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345614</th>\n",
       "      <td>1.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>15741.559570</td>\n",
       "      <td>465.45</td>\n",
       "      <td>42.720001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5863.0</td>\n",
       "      <td>...</td>\n",
       "      <td>177.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345615</th>\n",
       "      <td>1.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>15741.559570</td>\n",
       "      <td>465.45</td>\n",
       "      <td>42.720001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5863.0</td>\n",
       "      <td>...</td>\n",
       "      <td>187.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345616</th>\n",
       "      <td>1.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>15741.559570</td>\n",
       "      <td>465.45</td>\n",
       "      <td>42.720001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5863.0</td>\n",
       "      <td>...</td>\n",
       "      <td>177.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1128.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1345617 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ARR_DEL15  DISTANCE        NASDAQ     DOW  AIR_STOCK  YEAR  \\\n",
       "0              0.0    1158.0   6847.589844  570.89  49.000000   0.0   \n",
       "1              0.0    1158.0   6847.589844  570.89  49.000000   0.0   \n",
       "2              0.0     918.0   6847.589844  570.89  49.000000   0.0   \n",
       "3              0.0     918.0   6847.589844  570.89  49.000000   0.0   \n",
       "4              0.0    1021.0   6847.589844  570.89  49.000000   0.0   \n",
       "...            ...       ...           ...     ...        ...   ...   \n",
       "1345612        1.0     353.0  15741.559570  465.45  42.720001   4.0   \n",
       "1345613        1.0     650.0  15741.559570  465.45  42.720001   4.0   \n",
       "1345614        1.0     353.0  15741.559570  465.45  42.720001   4.0   \n",
       "1345615        1.0     353.0  15741.559570  465.45  42.720001   4.0   \n",
       "1345616        1.0     446.0  15741.559570  465.45  42.720001   4.0   \n",
       "\n",
       "         DAY_OF_MONTH  DAY_OF_WEEK  OP_UNIQUE_CARRIER  TAIL_NUM  ...  \\\n",
       "0                 0.0          4.0                0.0     115.0  ...   \n",
       "1                 0.0          4.0                0.0     115.0  ...   \n",
       "2                 0.0          4.0                0.0     115.0  ...   \n",
       "3                 0.0          4.0                0.0     115.0  ...   \n",
       "4                 0.0          4.0                0.0     116.0  ...   \n",
       "...               ...          ...                ...       ...  ...   \n",
       "1345612          28.0          3.0                9.0    5863.0  ...   \n",
       "1345613          28.0          3.0                9.0    5863.0  ...   \n",
       "1345614          28.0          3.0                9.0    5863.0  ...   \n",
       "1345615          28.0          3.0                9.0    5863.0  ...   \n",
       "1345616          28.0          3.0                9.0    5863.0  ...   \n",
       "\n",
       "         ORIGIN_CITY_MARKET_ID  ORIGIN_CITY_NAME  ORIGIN_STATE_FIPS  \\\n",
       "0                         17.0              80.0               41.0   \n",
       "1                        275.0             267.0               44.0   \n",
       "2                         17.0              80.0               41.0   \n",
       "3                         94.0             153.0                7.0   \n",
       "4                         55.0              66.0               33.0   \n",
       "...                        ...               ...                ...   \n",
       "1345612                  187.0             186.0                4.0   \n",
       "1345613                  211.0             161.0               23.0   \n",
       "1345614                  177.0             229.0                4.0   \n",
       "1345615                  187.0             186.0                4.0   \n",
       "1345616                  177.0             229.0                4.0   \n",
       "\n",
       "         ORIGIN_WAC  DEST_AIRPORT_ID  DEST_CITY_MARKET_ID  DEST_CITY_NAME  \\\n",
       "0              40.0            279.0                275.0           267.0   \n",
       "1              19.0             93.0                 17.0            80.0   \n",
       "2              40.0            169.0                 94.0           153.0   \n",
       "3              14.0             93.0                 17.0            80.0   \n",
       "4              24.0             93.0                 17.0            80.0   \n",
       "...             ...              ...                  ...             ...   \n",
       "1345612        49.0            231.0                177.0           229.0   \n",
       "1345613        33.0             23.0                 33.0            22.0   \n",
       "1345614        49.0            192.0                187.0           186.0   \n",
       "1345615        49.0            231.0                177.0           229.0   \n",
       "1345616        49.0            289.0                233.0           282.0   \n",
       "\n",
       "         DEST_STATE_FIPS  DEST_WAC  CRS_DEP_TIME  \n",
       "0                   44.0      19.0         298.0  \n",
       "1                   41.0      40.0         578.0  \n",
       "2                    7.0      14.0         783.0  \n",
       "3                   41.0      40.0        1038.0  \n",
       "4                   41.0      40.0         558.0  \n",
       "...                  ...       ...           ...  \n",
       "1345612              4.0      49.0         768.0  \n",
       "1345613             41.0      40.0         498.0  \n",
       "1345614              4.0      49.0         888.0  \n",
       "1345615              4.0      49.0        1008.0  \n",
       "1345616              4.0      49.0        1128.0  \n",
       "\n",
       "[1345617 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import load_data\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "df = load_data(separate=False)\n",
    "df_stock_only = df[['AIR_STOCK','NASDAQ', 'DOW', 'ARR_DEL15']]\n",
    "\n",
    "\n",
    "# get the string columns\n",
    "cat_cols = df.drop(columns=['ARR_DEL15', 'DISTANCE', 'NASDAQ', 'DOW', 'AIR_STOCK']).columns.tolist()\n",
    "\n",
    "\n",
    "# Fit and transform the encoder on the selected columns\n",
    "encoder = OrdinalEncoder()\n",
    "encoded_cols = encoder.fit_transform(df[cat_cols])\n",
    "\n",
    "# Convert the encoded columns to a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_cols, columns=cat_cols)\n",
    "\n",
    "# Drop the original columns from the DataFrame\n",
    "df = df.drop(columns=cat_cols)\n",
    "\n",
    "# Concatenate the encoded columns with the remaining columns\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARR_DEL15</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>DOW</th>\n",
       "      <th>AIR_STOCK</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>...</th>\n",
       "      <th>ORIGIN_CITY_MARKET_ID</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>ORIGIN_STATE_FIPS</th>\n",
       "      <th>ORIGIN_WAC</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEST_CITY_MARKET_ID</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEST_STATE_FIPS</th>\n",
       "      <th>DEST_WAC</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>6847.589844</td>\n",
       "      <td>570.89</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>6847.589844</td>\n",
       "      <td>570.89</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>6847.589844</td>\n",
       "      <td>570.89</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>210.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>6847.589844</td>\n",
       "      <td>570.89</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>6847.589844</td>\n",
       "      <td>570.89</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>249.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>807.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>12595.059570</td>\n",
       "      <td>331.28</td>\n",
       "      <td>44.160000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>953.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320077</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>15766.219727</td>\n",
       "      <td>468.55</td>\n",
       "      <td>18.049999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169049</th>\n",
       "      <td>0.0</td>\n",
       "      <td>812.0</td>\n",
       "      <td>15413.280273</td>\n",
       "      <td>462.84</td>\n",
       "      <td>17.120001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4312.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651039</th>\n",
       "      <td>0.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>8621.830078</td>\n",
       "      <td>475.67</td>\n",
       "      <td>55.470001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>...</td>\n",
       "      <td>210.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>638.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861586</th>\n",
       "      <td>0.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>8945.990234</td>\n",
       "      <td>495.32</td>\n",
       "      <td>58.660000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513344 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ARR_DEL15  DISTANCE        NASDAQ     DOW  AIR_STOCK  YEAR  \\\n",
       "11             1.0    1145.0   6847.589844  570.89  49.000000   0.0   \n",
       "20             1.0     204.0   6847.589844  570.89  49.000000   0.0   \n",
       "51             1.0     204.0   6847.589844  570.89  49.000000   0.0   \n",
       "58             1.0     590.0   6847.589844  570.89  49.000000   0.0   \n",
       "59             1.0     590.0   6847.589844  570.89  49.000000   0.0   \n",
       "...            ...       ...           ...     ...        ...   ...   \n",
       "959215         0.0     864.0  12595.059570  331.28  44.160000   3.0   \n",
       "1320077        0.0    1721.0  15766.219727  468.55  18.049999   4.0   \n",
       "1169049        0.0     812.0  15413.280273  462.84  17.120001   4.0   \n",
       "651039         0.0     781.0   8621.830078  475.67  55.470001   2.0   \n",
       "861586         0.0     852.0   8945.990234  495.32  58.660000   2.0   \n",
       "\n",
       "         DAY_OF_MONTH  DAY_OF_WEEK  OP_UNIQUE_CARRIER  TAIL_NUM  ...  \\\n",
       "11                0.0          4.0                0.0     121.0  ...   \n",
       "20                0.0          4.0                0.0     125.0  ...   \n",
       "51                0.0          4.0                0.0     146.0  ...   \n",
       "58                0.0          4.0                0.0     162.0  ...   \n",
       "59                0.0          4.0                0.0     162.0  ...   \n",
       "...               ...          ...                ...       ...  ...   \n",
       "959215           14.0          1.0                7.0     385.0  ...   \n",
       "1320077          27.0          2.0                0.0    4316.0  ...   \n",
       "1169049          12.0          0.0                0.0    4312.0  ...   \n",
       "651039            8.0          0.0                9.0    2241.0  ...   \n",
       "861586           28.0          0.0                3.0    1489.0  ...   \n",
       "\n",
       "         ORIGIN_CITY_MARKET_ID  ORIGIN_CITY_NAME  ORIGIN_STATE_FIPS  \\\n",
       "11                       178.0             200.0                7.0   \n",
       "20                       178.0             200.0                7.0   \n",
       "51                       210.0             319.0                7.0   \n",
       "58                        86.0              58.0               31.0   \n",
       "59                       249.0             333.0                7.0   \n",
       "...                        ...               ...                ...   \n",
       "959215                    78.0              62.0               11.0   \n",
       "1320077                   78.0              62.0               11.0   \n",
       "1169049                   17.0              80.0               41.0   \n",
       "651039                   210.0             319.0                7.0   \n",
       "861586                   130.0             203.0               21.0   \n",
       "\n",
       "         ORIGIN_WAC  DEST_AIRPORT_ID  DEST_CITY_MARKET_ID  DEST_CITY_NAME  \\\n",
       "11             14.0             99.0                104.0            87.0   \n",
       "20             14.0            332.0                210.0           319.0   \n",
       "51             14.0            214.0                178.0           200.0   \n",
       "58             17.0            248.0                249.0           333.0   \n",
       "59             14.0             72.0                 86.0            58.0   \n",
       "...             ...              ...                  ...             ...   \n",
       "959215         21.0            169.0                 94.0           153.0   \n",
       "1320077        21.0            299.0                 43.0           298.0   \n",
       "1169049        40.0             83.0                204.0            64.0   \n",
       "651039         14.0            148.0                111.0           143.0   \n",
       "861586         32.0             93.0                 17.0            80.0   \n",
       "\n",
       "         DEST_STATE_FIPS  DEST_WAC  CRS_DEP_TIME  \n",
       "11                  20.0      23.0         688.0  \n",
       "20                   7.0      14.0         287.0  \n",
       "51                   7.0      14.0         600.0  \n",
       "58                   7.0      14.0         653.0  \n",
       "59                  31.0      17.0         807.0  \n",
       "...                  ...       ...           ...  \n",
       "959215               7.0      14.0         953.0  \n",
       "1320077             45.0      51.0         833.0  \n",
       "1169049             15.0      27.0         613.0  \n",
       "651039              41.0      40.0         638.0  \n",
       "861586              41.0      40.0         313.0  \n",
       "\n",
       "[513344 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Determine the class with the fewer samples.\n",
    "counts = df_stock_only['ARR_DEL15'].value_counts()\n",
    "minority_class = counts.idxmin()\n",
    "minority_count = counts[minority_class]\n",
    "\n",
    "# Select a random sample of the larger class with the same size as the smaller class.\n",
    "majority_class = 1 - minority_class\n",
    "majority_count = counts[majority_class]\n",
    "majority_sample = df_stock_only[df_stock_only['ARR_DEL15'] == majority_class].sample(n=minority_count, random_state=0)\n",
    "\n",
    "# Combine the two classes into a single DataFrame.\n",
    "minority_df = df_stock_only[df_stock_only['ARR_DEL15'] == minority_class]\n",
    "balanced_df_stock_only = pd.concat([minority_df, majority_sample], axis=0)\n",
    "\n",
    "minority_df = df[df['ARR_DEL15'] == minority_class]\n",
    "majority_sample = df[df['ARR_DEL15'] == majority_class].sample(n=minority_count, random_state=0)\n",
    "balanced_df = pd.concat([minority_df, majority_sample], axis=0)\n",
    "\n",
    "balanced_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(balanced_df_stock_only.drop(columns=['ARR_DEL15']), balanced_df_stock_only['ARR_DEL15'], test_size=0.2, stratify=balanced_df_stock_only['ARR_DEL15'], random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best depth: 22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': [i for i in range(1,25 ,1)]}\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, verbose=3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best depth found by the grid search\n",
    "print(\"Best depth:\", grid_search.best_params_['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Depth:  22\n",
      "Number of leaves:  974\n",
      "Accuracy: 0.6299856821435876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.62      0.63     51335\n",
      "         1.0       0.63      0.64      0.63     51334\n",
      "\n",
      "    accuracy                           0.63    102669\n",
      "   macro avg       0.63      0.63      0.63    102669\n",
      "weighted avg       0.63      0.63      0.63    102669\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, PrecisionRecallDisplay\n",
    "\n",
    "# Train the decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth = 22)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "  \n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Tree Depth: ', clf.get_depth())\n",
    "print('Number of leaves: ', clf.get_n_leaves())\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# print the report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "display = PrecisionRecallDisplay.from_predictions(y_test, y_pred)\n",
    "_ = display.ax_.set_title(\"Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importances = pd.Series(clf.feature_importances_, index=X_train.columns)\n",
    "feature_importances.sort_values().plot(kind='barh')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 500building tree 2 of 500\n",
      "building tree 3 of 500\n",
      "\n",
      "building tree 4 of 500\n",
      "building tree 5 of 500\n",
      "building tree 6 of 500\n",
      "building tree 7 of 500\n",
      "building tree 8 of 500\n",
      "building tree 9 of 500\n",
      "building tree 10 of 500\n",
      "building tree 11 of 500\n",
      "building tree 12 of 500\n",
      "building tree 13 of 500\n",
      "building tree 14 of 500\n",
      "building tree 15 of 500\n",
      "building tree 16 of 500\n",
      "building tree 17 of 500\n",
      "building tree 18 of 500\n",
      "building tree 19 of 500\n",
      "building tree 20 of 500\n",
      "building tree 21 of 500\n",
      "building tree 22 of 500\n",
      "building tree 23 of 500\n",
      "building tree 24 of 500\n",
      "building tree 25 of 500\n",
      "building tree 26 of 500\n",
      "building tree 27 of 500\n",
      "building tree 28 of 500\n",
      "building tree 29 of 500\n",
      "building tree 30 of 500\n",
      "building tree 31 of 500\n",
      "building tree 32 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 33 of 500\n",
      "building tree 34 of 500\n",
      "building tree 35 of 500\n",
      "building tree 36 of 500\n",
      "building tree 37 of 500\n",
      "building tree 38 of 500\n",
      "building tree 39 of 500\n",
      "building tree 40 of 500\n",
      "building tree 41 of 500\n",
      "building tree 42 of 500\n",
      "building tree 43 of 500\n",
      "building tree 44 of 500\n",
      "building tree 45 of 500\n",
      "building tree 46 of 500\n",
      "building tree 47 of 500\n",
      "building tree 48 of 500\n",
      "building tree 49 of 500\n",
      "building tree 50 of 500\n",
      "building tree 51 of 500\n",
      "building tree 52 of 500\n",
      "building tree 53 of 500\n",
      "building tree 54 of 500\n",
      "building tree 55 of 500\n",
      "building tree 56 of 500\n",
      "building tree 57 of 500\n",
      "building tree 58 of 500\n",
      "building tree 59 of 500\n",
      "building tree 60 of 500\n",
      "building tree 61 of 500\n",
      "building tree 62 of 500\n",
      "building tree 63 of 500\n",
      "building tree 64 of 500\n",
      "building tree 65 of 500\n",
      "building tree 66 of 500\n",
      "building tree 67 of 500\n",
      "building tree 68 of 500\n",
      "building tree 69 of 500\n",
      "building tree 70 of 500\n",
      "building tree 71 of 500\n",
      "building tree 72 of 500\n",
      "building tree 73 of 500\n",
      "building tree 74 of 500\n",
      "building tree 75 of 500\n",
      "building tree 76 of 500\n",
      "building tree 77 of 500\n",
      "building tree 78 of 500\n",
      "building tree 79 of 500\n",
      "building tree 80 of 500\n",
      "building tree 81 of 500\n",
      "building tree 82 of 500\n",
      "building tree 83 of 500\n",
      "building tree 84 of 500\n",
      "building tree 85 of 500\n",
      "building tree 86 of 500\n",
      "building tree 87 of 500\n",
      "building tree 88 of 500\n",
      "building tree 89 of 500\n",
      "building tree 90 of 500\n",
      "building tree 91 of 500\n",
      "building tree 92 of 500\n",
      "building tree 93 of 500\n",
      "building tree 94 of 500\n",
      "building tree 95 of 500\n",
      "building tree 96 of 500\n",
      "building tree 97 of 500\n",
      "building tree 98 of 500\n",
      "building tree 99 of 500\n",
      "building tree 100 of 500\n",
      "building tree 101 of 500\n",
      "building tree 102 of 500\n",
      "building tree 103 of 500\n",
      "building tree 104 of 500\n",
      "building tree 105 of 500\n",
      "building tree 106 of 500\n",
      "building tree 107 of 500\n",
      "building tree 108 of 500\n",
      "building tree 109 of 500\n",
      "building tree 110 of 500\n",
      "building tree 111 of 500\n",
      "building tree 112 of 500\n",
      "building tree 113 of 500\n",
      "building tree 114 of 500\n",
      "building tree 115 of 500\n",
      "building tree 116 of 500\n",
      "building tree 117 of 500\n",
      "building tree 118 of 500\n",
      "building tree 119 of 500\n",
      "building tree 120 of 500\n",
      "building tree 121 of 500\n",
      "building tree 122 of 500\n",
      "building tree 123 of 500\n",
      "building tree 124 of 500\n",
      "building tree 125 of 500\n",
      "building tree 126 of 500\n",
      "building tree 127 of 500\n",
      "building tree 128 of 500\n",
      "building tree 129 of 500\n",
      "building tree 130 of 500\n",
      "building tree 131 of 500\n",
      "building tree 132 of 500\n",
      "building tree 133 of 500\n",
      "building tree 134 of 500\n",
      "building tree 135 of 500\n",
      "building tree 136 of 500\n",
      "building tree 137 of 500\n",
      "building tree 138 of 500\n",
      "building tree 139 of 500\n",
      "building tree 140 of 500\n",
      "building tree 141 of 500\n",
      "building tree 142 of 500\n",
      "building tree 143 of 500\n",
      "building tree 144 of 500\n",
      "building tree 145 of 500\n",
      "building tree 146 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    5.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 147 of 500\n",
      "building tree 148 of 500\n",
      "building tree 149 of 500\n",
      "building tree 150 of 500\n",
      "building tree 151 of 500\n",
      "building tree 152 of 500building tree 153 of 500\n",
      "\n",
      "building tree 154 of 500\n",
      "building tree 155 of 500\n",
      "building tree 156 of 500\n",
      "building tree 157 of 500\n",
      "building tree 158 of 500\n",
      "building tree 159 of 500\n",
      "building tree 160 of 500\n",
      "building tree 161 of 500\n",
      "building tree 162 of 500\n",
      "building tree 163 of 500\n",
      "building tree 164 of 500\n",
      "building tree 165 of 500\n",
      "building tree 166 of 500\n",
      "building tree 167 of 500\n",
      "building tree 168 of 500\n",
      "building tree 169 of 500\n",
      "building tree 170 of 500\n",
      "building tree 171 of 500\n",
      "building tree 172 of 500\n",
      "building tree 173 of 500\n",
      "building tree 174 of 500\n",
      "building tree 175 of 500\n",
      "building tree 176 of 500\n",
      "building tree 177 of 500\n",
      "building tree 178 of 500\n",
      "building tree 179 of 500\n",
      "building tree 180 of 500\n",
      "building tree 181 of 500\n",
      "building tree 182 of 500\n",
      "building tree 183 of 500\n",
      "building tree 184 of 500\n",
      "building tree 185 of 500\n",
      "building tree 186 of 500\n",
      "building tree 187 of 500\n",
      "building tree 188 of 500\n",
      "building tree 189 of 500\n",
      "building tree 190 of 500\n",
      "building tree 191 of 500\n",
      "building tree 192 of 500\n",
      "building tree 193 of 500\n",
      "building tree 194 of 500\n",
      "building tree 195 of 500\n",
      "building tree 196 of 500\n",
      "building tree 197 of 500\n",
      "building tree 198 of 500\n",
      "building tree 199 of 500\n",
      "building tree 200 of 500\n",
      "building tree 201 of 500\n",
      "building tree 202 of 500\n",
      "building tree 203 of 500\n",
      "building tree 204 of 500\n",
      "building tree 205 of 500\n",
      "building tree 206 of 500\n",
      "building tree 207 of 500\n",
      "building tree 208 of 500\n",
      "building tree 209 of 500\n",
      "building tree 210 of 500\n",
      "building tree 211 of 500\n",
      "building tree 212 of 500\n",
      "building tree 213 of 500\n",
      "building tree 214 of 500\n",
      "building tree 215 of 500\n",
      "building tree 216 of 500\n",
      "building tree 217 of 500\n",
      "building tree 218 of 500\n",
      "building tree 219 of 500\n",
      "building tree 220 of 500\n",
      "building tree 221 of 500\n",
      "building tree 222 of 500\n",
      "building tree 223 of 500\n",
      "building tree 224 of 500\n",
      "building tree 225 of 500\n",
      "building tree 226 of 500\n",
      "building tree 227 of 500\n",
      "building tree 228 of 500\n",
      "building tree 229 of 500\n",
      "building tree 230 of 500\n",
      "building tree 231 of 500\n",
      "building tree 232 of 500\n",
      "building tree 233 of 500\n",
      "building tree 234 of 500\n",
      "building tree 235 of 500\n",
      "building tree 236 of 500\n",
      "building tree 237 of 500\n",
      "building tree 238 of 500\n",
      "building tree 239 of 500\n",
      "building tree 240 of 500\n",
      "building tree 241 of 500\n",
      "building tree 242 of 500\n",
      "building tree 243 of 500\n",
      "building tree 244 of 500\n",
      "building tree 245 of 500\n",
      "building tree 246 of 500\n",
      "building tree 247 of 500\n",
      "building tree 248 of 500\n",
      "building tree 249 of 500\n",
      "building tree 250 of 500\n",
      "building tree 251 of 500\n",
      "building tree 252 of 500\n",
      "building tree 253 of 500\n",
      "building tree 254 of 500\n",
      "building tree 255 of 500\n",
      "building tree 256 of 500\n",
      "building tree 257 of 500\n",
      "building tree 258 of 500\n",
      "building tree 259 of 500\n",
      "building tree 260 of 500\n",
      "building tree 261 of 500\n",
      "building tree 262 of 500\n",
      "building tree 263 of 500\n",
      "building tree 264 of 500\n",
      "building tree 265 of 500\n",
      "building tree 266 of 500\n",
      "building tree 267 of 500\n",
      "building tree 268 of 500\n",
      "building tree 269 of 500\n",
      "building tree 270 of 500\n",
      "building tree 271 of 500\n",
      "building tree 272 of 500\n",
      "building tree 273 of 500\n",
      "building tree 274 of 500\n",
      "building tree 275 of 500\n",
      "building tree 276 of 500\n",
      "building tree 277 of 500\n",
      "building tree 278 of 500\n",
      "building tree 279 of 500\n",
      "building tree 280 of 500\n",
      "building tree 281 of 500\n",
      "building tree 282 of 500\n",
      "building tree 283 of 500\n",
      "building tree 284 of 500\n",
      "building tree 285 of 500\n",
      "building tree 286 of 500\n",
      "building tree 287 of 500\n",
      "building tree 288 of 500\n",
      "building tree 289 of 500\n",
      "building tree 290 of 500\n",
      "building tree 291 of 500\n",
      "building tree 292 of 500\n",
      "building tree 293 of 500\n",
      "building tree 294 of 500\n",
      "building tree 295 of 500\n",
      "building tree 296 of 500\n",
      "building tree 297 of 500\n",
      "building tree 298 of 500\n",
      "building tree 299 of 500\n",
      "building tree 300 of 500\n",
      "building tree 301 of 500\n",
      "building tree 302 of 500\n",
      "building tree 303 of 500\n",
      "building tree 304 of 500\n",
      "building tree 305 of 500\n",
      "building tree 306 of 500\n",
      "building tree 307 of 500\n",
      "building tree 308 of 500\n",
      "building tree 309 of 500\n",
      "building tree 310 of 500\n",
      "building tree 311 of 500\n",
      "building tree 312 of 500\n",
      "building tree 313 of 500\n",
      "building tree 314 of 500\n",
      "building tree 315 of 500\n",
      "building tree 316 of 500\n",
      "building tree 317 of 500\n",
      "building tree 318 of 500\n",
      "building tree 319 of 500\n",
      "building tree 320 of 500\n",
      "building tree 321 of 500\n",
      "building tree 322 of 500\n",
      "building tree 323 of 500\n",
      "building tree 324 of 500\n",
      "building tree 325 of 500\n",
      "building tree 326 of 500\n",
      "building tree 327 of 500\n",
      "building tree 328 of 500\n",
      "building tree 329 of 500\n",
      "building tree 330 of 500\n",
      "building tree 331 of 500\n",
      "building tree 332 of 500\n",
      "building tree 333 of 500\n",
      "building tree 334 of 500\n",
      "building tree 335 of 500\n",
      "building tree 336 of 500\n",
      "building tree 337 of 500\n",
      "building tree 338 of 500\n",
      "building tree 339 of 500\n",
      "building tree 340 of 500\n",
      "building tree 341 of 500\n",
      "building tree 342 of 500\n",
      "building tree 343 of 500\n",
      "building tree 344 of 500\n",
      "building tree 345 of 500\n",
      "building tree 346 of 500\n",
      "building tree 347 of 500\n",
      "building tree 348 of 500\n",
      "building tree 349 of 500\n",
      "building tree 350 of 500\n",
      "building tree 351 of 500\n",
      "building tree 352 of 500\n",
      "building tree 353 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   13.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 354 of 500\n",
      "building tree 355 of 500\n",
      "building tree 356 of 500\n",
      "building tree 357 of 500\n",
      "building tree 358 of 500\n",
      "building tree 359 of 500\n",
      "building tree 360 of 500\n",
      "building tree 361 of 500\n",
      "building tree 362 of 500\n",
      "building tree 363 of 500\n",
      "building tree 364 of 500\n",
      "building tree 365 of 500\n",
      "building tree 366 of 500\n",
      "building tree 367 of 500\n",
      "building tree 368 of 500\n",
      "building tree 369 of 500\n",
      "building tree 370 of 500\n",
      "building tree 371 of 500\n",
      "building tree 372 of 500\n",
      "building tree 373 of 500\n",
      "building tree 374 of 500\n",
      "building tree 375 of 500\n",
      "building tree 376 of 500\n",
      "building tree 377 of 500\n",
      "building tree 378 of 500\n",
      "building tree 379 of 500\n",
      "building tree 380 of 500\n",
      "building tree 381 of 500\n",
      "building tree 382 of 500\n",
      "building tree 383 of 500\n",
      "building tree 384 of 500\n",
      "building tree 385 of 500\n",
      "building tree 386 of 500\n",
      "building tree 387 of 500\n",
      "building tree 388 of 500\n",
      "building tree 389 of 500\n",
      "building tree 390 of 500\n",
      "building tree 391 of 500\n",
      "building tree 392 of 500\n",
      "building tree 393 of 500\n",
      "building tree 394 of 500\n",
      "building tree 395 of 500\n",
      "building tree 396 of 500\n",
      "building tree 397 of 500\n",
      "building tree 398 of 500\n",
      "building tree 399 of 500\n",
      "building tree 400 of 500\n",
      "building tree 401 of 500\n",
      "building tree 402 of 500\n",
      "building tree 403 of 500\n",
      "building tree 404 of 500\n",
      "building tree 405 of 500\n",
      "building tree 406 of 500\n",
      "building tree 407 of 500\n",
      "building tree 408 of 500\n",
      "building tree 409 of 500\n",
      "building tree 410 of 500\n",
      "building tree 411 of 500\n",
      "building tree 412 of 500\n",
      "building tree 413 of 500\n",
      "building tree 414 of 500\n",
      "building tree 415 of 500\n",
      "building tree 416 of 500\n",
      "building tree 417 of 500\n",
      "building tree 418 of 500\n",
      "building tree 419 of 500\n",
      "building tree 420 of 500\n",
      "building tree 421 of 500\n",
      "building tree 422 of 500\n",
      "building tree 423 of 500\n",
      "building tree 424 of 500\n",
      "building tree 425 of 500\n",
      "building tree 426 of 500\n",
      "building tree 427 of 500\n",
      "building tree 428 of 500\n",
      "building tree 429 of 500\n",
      "building tree 430 of 500\n",
      "building tree 431 of 500\n",
      "building tree 432 of 500\n",
      "building tree 433 of 500\n",
      "building tree 434 of 500\n",
      "building tree 435 of 500\n",
      "building tree 436 of 500\n",
      "building tree 437 of 500\n",
      "building tree 438 of 500\n",
      "building tree 439 of 500\n",
      "building tree 440 of 500\n",
      "building tree 441 of 500\n",
      "building tree 442 of 500\n",
      "building tree 443 of 500\n",
      "building tree 444 of 500\n",
      "building tree 445 of 500\n",
      "building tree 446 of 500\n",
      "building tree 447 of 500\n",
      "building tree 448 of 500\n",
      "building tree 449 of 500\n",
      "building tree 450 of 500\n",
      "building tree 451 of 500\n",
      "building tree 452 of 500\n",
      "building tree 453 of 500\n",
      "building tree 454 of 500\n",
      "building tree 455 of 500\n",
      "building tree 456 of 500\n",
      "building tree 457 of 500\n",
      "building tree 458 of 500\n",
      "building tree 459 of 500\n",
      "building tree 460 of 500\n",
      "building tree 461 of 500\n",
      "building tree 462 of 500\n",
      "building tree 463 of 500\n",
      "building tree 464 of 500\n",
      "building tree 465 of 500\n",
      "building tree 466 of 500\n",
      "building tree 467 of 500\n",
      "building tree 468 of 500\n",
      "building tree 469 of 500\n",
      "building tree 470 of 500\n",
      "building tree 471 of 500\n",
      "building tree 472 of 500\n",
      "building tree 473 of 500\n",
      "building tree 474 of 500\n",
      "building tree 475 of 500\n",
      "building tree 476 of 500\n",
      "building tree 477 of 500\n",
      "building tree 478 of 500\n",
      "building tree 479 of 500\n",
      "building tree 480 of 500\n",
      "building tree 481 of 500\n",
      "building tree 482 of 500\n",
      "building tree 483 of 500\n",
      "building tree 484 of 500\n",
      "building tree 485 of 500\n",
      "building tree 486 of 500\n",
      "building tree 487 of 500\n",
      "building tree 488 of 500\n",
      "building tree 489 of 500\n",
      "building tree 490 of 500\n",
      "building tree 491 of 500\n",
      "building tree 492 of 500\n",
      "building tree 493 of 500\n",
      "building tree 494 of 500\n",
      "building tree 495 of 500\n",
      "building tree 496 of 500\n",
      "building tree 497 of 500\n",
      "building tree 498 of 500\n",
      "building tree 499 of 500\n",
      "building tree 500 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   19.9s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 130 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 333 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 500 out of 500 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.6299564620284603\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.62      0.63     51335\n",
      "         1.0       0.63      0.64      0.63     51334\n",
      "\n",
      "    accuracy                           0.63    102669\n",
      "   macro avg       0.63      0.63      0.63    102669\n",
      "weighted avg       0.63      0.63      0.63    102669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a random forest classifier object\n",
    "rf = RandomForestClassifier(n_estimators = 500, n_jobs=-1, verbose=2, random_state=0)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosted tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.009 GB of training data: 0.050 s\n",
      "Binning 0.001 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.68670, val loss: 0.68671, in 0.019s\n",
      "[2/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.68136, val loss: 0.68136, in 0.019s\n",
      "[3/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.67683, val loss: 0.67680, in 0.017s\n",
      "[4/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.67328, val loss: 0.67323, in 0.016s\n",
      "[5/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.67002, val loss: 0.67000, in 0.019s\n",
      "[6/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.66740, val loss: 0.66743, in 0.019s\n",
      "[7/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.66511, val loss: 0.66520, in 0.019s\n",
      "[8/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.66311, val loss: 0.66325, in 0.016s\n",
      "[9/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.66141, val loss: 0.66152, in 0.016s\n",
      "[10/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.65982, val loss: 0.65992, in 0.018s\n",
      "[11/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.65843, val loss: 0.65859, in 0.018s\n",
      "[12/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.65710, val loss: 0.65719, in 0.018s\n",
      "[13/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.65582, val loss: 0.65593, in 0.017s\n",
      "[14/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.65485, val loss: 0.65492, in 0.018s\n",
      "[15/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.65402, val loss: 0.65403, in 0.022s\n",
      "[16/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.65330, val loss: 0.65332, in 0.017s\n",
      "[17/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.65256, val loss: 0.65262, in 0.017s\n",
      "[18/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.65190, val loss: 0.65194, in 0.017s\n",
      "[19/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.65140, val loss: 0.65147, in 0.018s\n",
      "[20/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.65070, val loss: 0.65077, in 0.018s\n",
      "[21/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.65008, val loss: 0.65020, in 0.017s\n",
      "[22/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64952, val loss: 0.64967, in 0.018s\n",
      "[23/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64909, val loss: 0.64926, in 0.018s\n",
      "[24/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64869, val loss: 0.64886, in 0.016s\n",
      "[25/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64830, val loss: 0.64848, in 0.019s\n",
      "[26/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.64798, val loss: 0.64817, in 0.029s\n",
      "[27/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.64763, val loss: 0.64784, in 0.017s\n",
      "[28/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64723, val loss: 0.64745, in 0.018s\n",
      "[29/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.64692, val loss: 0.64719, in 0.018s\n",
      "[30/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.64659, val loss: 0.64687, in 0.018s\n",
      "[31/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.64632, val loss: 0.64665, in 0.017s\n",
      "[32/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64610, val loss: 0.64646, in 0.018s\n",
      "[33/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64586, val loss: 0.64620, in 0.017s\n",
      "[34/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64570, val loss: 0.64605, in 0.015s\n",
      "[35/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64554, val loss: 0.64586, in 0.016s\n",
      "[36/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.64533, val loss: 0.64570, in 0.018s\n",
      "[37/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64511, val loss: 0.64553, in 0.017s\n",
      "[38/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64493, val loss: 0.64535, in 0.017s\n",
      "[39/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64469, val loss: 0.64516, in 0.017s\n",
      "[40/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64451, val loss: 0.64498, in 0.015s\n",
      "[41/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64437, val loss: 0.64489, in 0.015s\n",
      "[42/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64418, val loss: 0.64473, in 0.016s\n",
      "[43/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64405, val loss: 0.64464, in 0.016s\n",
      "[44/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64390, val loss: 0.64449, in 0.016s\n",
      "[45/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64378, val loss: 0.64441, in 0.016s\n",
      "[46/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64360, val loss: 0.64422, in 0.016s\n",
      "[47/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.64342, val loss: 0.64405, in 0.017s\n",
      "[48/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.64333, val loss: 0.64397, in 0.015s\n",
      "[49/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64323, val loss: 0.64390, in 0.016s\n",
      "[50/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64313, val loss: 0.64379, in 0.015s\n",
      "[51/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64298, val loss: 0.64368, in 0.016s\n",
      "[52/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.64283, val loss: 0.64354, in 0.016s\n",
      "[53/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.64273, val loss: 0.64346, in 0.016s\n",
      "[54/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.64257, val loss: 0.64330, in 0.017s\n",
      "[55/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64244, val loss: 0.64319, in 0.017s\n",
      "[56/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.64234, val loss: 0.64310, in 0.014s\n",
      "[57/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.64223, val loss: 0.64301, in 0.015s\n",
      "[58/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64213, val loss: 0.64292, in 0.015s\n",
      "[59/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64206, val loss: 0.64289, in 0.015s\n",
      "[60/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64200, val loss: 0.64285, in 0.016s\n",
      "[61/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64187, val loss: 0.64272, in 0.016s\n",
      "[62/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64176, val loss: 0.64260, in 0.017s\n",
      "[63/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64168, val loss: 0.64254, in 0.016s\n",
      "[64/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64160, val loss: 0.64247, in 0.015s\n",
      "[65/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64153, val loss: 0.64243, in 0.016s\n",
      "[66/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64143, val loss: 0.64235, in 0.016s\n",
      "[67/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64138, val loss: 0.64233, in 0.016s\n",
      "[68/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64132, val loss: 0.64226, in 0.017s\n",
      "[69/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64122, val loss: 0.64214, in 0.018s\n",
      "[70/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64114, val loss: 0.64207, in 0.015s\n",
      "[71/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64105, val loss: 0.64197, in 0.016s\n",
      "[72/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64091, val loss: 0.64184, in 0.018s\n",
      "[73/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64087, val loss: 0.64182, in 0.015s\n",
      "[74/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64079, val loss: 0.64174, in 0.015s\n",
      "[75/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64072, val loss: 0.64169, in 0.015s\n",
      "[76/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64067, val loss: 0.64165, in 0.029s\n",
      "[77/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.64057, val loss: 0.64157, in 0.019s\n",
      "[78/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64054, val loss: 0.64156, in 0.017s\n",
      "[79/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64047, val loss: 0.64152, in 0.018s\n",
      "[80/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.64041, val loss: 0.64146, in 0.014s\n",
      "[81/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.64038, val loss: 0.64144, in 0.015s\n",
      "[82/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64033, val loss: 0.64137, in 0.017s\n",
      "[83/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.64025, val loss: 0.64131, in 0.016s\n",
      "[84/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64017, val loss: 0.64124, in 0.017s\n",
      "[85/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.64012, val loss: 0.64121, in 0.016s\n",
      "[86/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.64007, val loss: 0.64117, in 0.016s\n",
      "[87/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63998, val loss: 0.64109, in 0.015s\n",
      "[88/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63992, val loss: 0.64102, in 0.015s\n",
      "[89/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63985, val loss: 0.64097, in 0.015s\n",
      "[90/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63979, val loss: 0.64095, in 0.015s\n",
      "[91/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63972, val loss: 0.64089, in 0.016s\n",
      "[92/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63968, val loss: 0.64084, in 0.016s\n",
      "[93/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.63965, val loss: 0.64081, in 0.016s\n",
      "[94/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63960, val loss: 0.64077, in 0.016s\n",
      "[95/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63954, val loss: 0.64069, in 0.016s\n",
      "[96/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63950, val loss: 0.64066, in 0.016s\n",
      "[97/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63946, val loss: 0.64063, in 0.015s\n",
      "[98/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63941, val loss: 0.64059, in 0.016s\n",
      "[99/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63938, val loss: 0.64056, in 0.015s\n",
      "[100/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63934, val loss: 0.64053, in 0.014s\n",
      "[101/10000] 1 tree, 31 leaves, max depth = 18, train loss: 0.63929, val loss: 0.64050, in 0.015s\n",
      "[102/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63924, val loss: 0.64044, in 0.016s\n",
      "[103/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63922, val loss: 0.64043, in 0.015s\n",
      "[104/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63918, val loss: 0.64041, in 0.017s\n",
      "[105/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63913, val loss: 0.64037, in 0.017s\n",
      "[106/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63908, val loss: 0.64033, in 0.016s\n",
      "[107/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63903, val loss: 0.64030, in 0.017s\n",
      "[108/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63898, val loss: 0.64027, in 0.015s\n",
      "[109/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63894, val loss: 0.64023, in 0.015s\n",
      "[110/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63888, val loss: 0.64017, in 0.015s\n",
      "[111/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63884, val loss: 0.64015, in 0.015s\n",
      "[112/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63882, val loss: 0.64011, in 0.015s\n",
      "[113/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.63879, val loss: 0.64008, in 0.017s\n",
      "[114/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63874, val loss: 0.64005, in 0.014s\n",
      "[115/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.63871, val loss: 0.64003, in 0.015s\n",
      "[116/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63866, val loss: 0.63999, in 0.016s\n",
      "[117/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63860, val loss: 0.63996, in 0.019s\n",
      "[118/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63856, val loss: 0.63994, in 0.016s\n",
      "[119/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63851, val loss: 0.63991, in 0.016s\n",
      "[120/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63849, val loss: 0.63989, in 0.015s\n",
      "[121/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63847, val loss: 0.63988, in 0.016s\n",
      "[122/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63843, val loss: 0.63985, in 0.015s\n",
      "[123/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63838, val loss: 0.63980, in 0.023s\n",
      "[124/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63834, val loss: 0.63978, in 0.016s\n",
      "[125/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63833, val loss: 0.63976, in 0.015s\n",
      "[126/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63830, val loss: 0.63975, in 0.015s\n",
      "[127/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.63828, val loss: 0.63973, in 0.016s\n",
      "[128/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63825, val loss: 0.63971, in 0.015s\n",
      "[129/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.63822, val loss: 0.63966, in 0.014s\n",
      "[130/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63818, val loss: 0.63962, in 0.040s\n",
      "[131/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.63815, val loss: 0.63959, in 0.015s\n",
      "[132/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63812, val loss: 0.63956, in 0.016s\n",
      "[133/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63809, val loss: 0.63953, in 0.015s\n",
      "[134/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63806, val loss: 0.63951, in 0.014s\n",
      "[135/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63802, val loss: 0.63948, in 0.014s\n",
      "[136/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63799, val loss: 0.63947, in 0.014s\n",
      "[137/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63798, val loss: 0.63946, in 0.016s\n",
      "[138/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63795, val loss: 0.63944, in 0.023s\n",
      "[139/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63793, val loss: 0.63942, in 0.014s\n",
      "[140/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63791, val loss: 0.63940, in 0.014s\n",
      "[141/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63790, val loss: 0.63939, in 0.013s\n",
      "[142/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63787, val loss: 0.63936, in 0.014s\n",
      "[143/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63784, val loss: 0.63934, in 0.016s\n",
      "[144/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63782, val loss: 0.63932, in 0.015s\n",
      "[145/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63778, val loss: 0.63929, in 0.014s\n",
      "[146/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63776, val loss: 0.63928, in 0.015s\n",
      "[147/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63774, val loss: 0.63928, in 0.013s\n",
      "[148/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63772, val loss: 0.63926, in 0.014s\n",
      "[149/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.63771, val loss: 0.63925, in 0.012s\n",
      "[150/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63768, val loss: 0.63922, in 0.014s\n",
      "[151/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63765, val loss: 0.63921, in 0.014s\n",
      "[152/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63763, val loss: 0.63920, in 0.013s\n",
      "[153/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63762, val loss: 0.63919, in 0.012s\n",
      "[154/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63761, val loss: 0.63917, in 0.014s\n",
      "[155/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63758, val loss: 0.63915, in 0.015s\n",
      "[156/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.63755, val loss: 0.63912, in 0.016s\n",
      "[157/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63752, val loss: 0.63910, in 0.013s\n",
      "[158/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63751, val loss: 0.63910, in 0.014s\n",
      "[159/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63750, val loss: 0.63910, in 0.013s\n",
      "[160/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63748, val loss: 0.63907, in 0.013s\n",
      "[161/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63745, val loss: 0.63904, in 0.015s\n",
      "[162/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63743, val loss: 0.63903, in 0.014s\n",
      "[163/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63741, val loss: 0.63901, in 0.014s\n",
      "[164/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63738, val loss: 0.63899, in 0.015s\n",
      "[165/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63737, val loss: 0.63899, in 0.015s\n",
      "[166/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63736, val loss: 0.63898, in 0.017s\n",
      "[167/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.63735, val loss: 0.63898, in 0.015s\n",
      "[168/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63734, val loss: 0.63898, in 0.014s\n",
      "[169/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63731, val loss: 0.63895, in 0.015s\n",
      "[170/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63729, val loss: 0.63893, in 0.015s\n",
      "[171/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63727, val loss: 0.63891, in 0.014s\n",
      "[172/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63724, val loss: 0.63891, in 0.016s\n",
      "[173/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63722, val loss: 0.63889, in 0.016s\n",
      "[174/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63720, val loss: 0.63888, in 0.017s\n",
      "[175/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63719, val loss: 0.63887, in 0.015s\n",
      "[176/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63717, val loss: 0.63885, in 0.014s\n",
      "[177/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63716, val loss: 0.63885, in 0.014s\n",
      "[178/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63716, val loss: 0.63886, in 0.014s\n",
      "[179/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63714, val loss: 0.63884, in 0.014s\n",
      "[180/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63713, val loss: 0.63883, in 0.012s\n",
      "[181/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63711, val loss: 0.63882, in 0.016s\n",
      "[182/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63708, val loss: 0.63879, in 0.014s\n",
      "[183/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63707, val loss: 0.63878, in 0.016s\n",
      "[184/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63705, val loss: 0.63877, in 0.015s\n",
      "[185/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63703, val loss: 0.63876, in 0.015s\n",
      "[186/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63701, val loss: 0.63874, in 0.016s\n",
      "[187/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63699, val loss: 0.63873, in 0.013s\n",
      "[188/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63697, val loss: 0.63872, in 0.014s\n",
      "[189/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63696, val loss: 0.63871, in 0.015s\n",
      "[190/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63694, val loss: 0.63870, in 0.015s\n",
      "[191/10000] 1 tree, 31 leaves, max depth = 17, train loss: 0.63693, val loss: 0.63870, in 0.014s\n",
      "[192/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63691, val loss: 0.63868, in 0.015s\n",
      "[193/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63691, val loss: 0.63867, in 0.014s\n",
      "[194/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63689, val loss: 0.63865, in 0.014s\n",
      "[195/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63688, val loss: 0.63865, in 0.014s\n",
      "[196/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63687, val loss: 0.63864, in 0.016s\n",
      "[197/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.63685, val loss: 0.63862, in 0.017s\n",
      "[198/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63684, val loss: 0.63862, in 0.015s\n",
      "[199/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.63684, val loss: 0.63862, in 0.014s\n",
      "[200/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63683, val loss: 0.63862, in 0.015s\n",
      "[201/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63681, val loss: 0.63861, in 0.015s\n",
      "[202/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63680, val loss: 0.63860, in 0.016s\n",
      "[203/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63679, val loss: 0.63859, in 0.017s\n",
      "[204/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63677, val loss: 0.63858, in 0.016s\n",
      "[205/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63676, val loss: 0.63858, in 0.015s\n",
      "[206/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63675, val loss: 0.63857, in 0.020s\n",
      "[207/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63674, val loss: 0.63856, in 0.017s\n",
      "[208/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63672, val loss: 0.63855, in 0.016s\n",
      "[209/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63671, val loss: 0.63855, in 0.015s\n",
      "[210/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63670, val loss: 0.63854, in 0.015s\n",
      "[211/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63669, val loss: 0.63853, in 0.015s\n",
      "[212/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63668, val loss: 0.63852, in 0.022s\n",
      "[213/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63666, val loss: 0.63850, in 0.016s\n",
      "[214/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63666, val loss: 0.63850, in 0.015s\n",
      "[215/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63664, val loss: 0.63849, in 0.016s\n",
      "[216/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63663, val loss: 0.63849, in 0.016s\n",
      "[217/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63662, val loss: 0.63849, in 0.016s\n",
      "[218/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63661, val loss: 0.63848, in 0.016s\n",
      "[219/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63660, val loss: 0.63847, in 0.016s\n",
      "[220/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63659, val loss: 0.63846, in 0.014s\n",
      "[221/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63658, val loss: 0.63845, in 0.016s\n",
      "[222/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63657, val loss: 0.63845, in 0.016s\n",
      "[223/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63656, val loss: 0.63844, in 0.013s\n",
      "[224/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63656, val loss: 0.63843, in 0.015s\n",
      "[225/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63655, val loss: 0.63843, in 0.016s\n",
      "[226/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63654, val loss: 0.63843, in 0.015s\n",
      "[227/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63653, val loss: 0.63842, in 0.015s\n",
      "[228/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63652, val loss: 0.63841, in 0.014s\n",
      "[229/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63652, val loss: 0.63841, in 0.014s\n",
      "[230/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.63651, val loss: 0.63840, in 0.015s\n",
      "[231/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63650, val loss: 0.63840, in 0.016s\n",
      "[232/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63649, val loss: 0.63839, in 0.016s\n",
      "[233/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63649, val loss: 0.63838, in 0.016s\n",
      "[234/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63648, val loss: 0.63838, in 0.015s\n",
      "[235/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.63647, val loss: 0.63837, in 0.015s\n",
      "[236/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63647, val loss: 0.63837, in 0.016s\n",
      "[237/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63647, val loss: 0.63836, in 0.014s\n",
      "[238/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63646, val loss: 0.63835, in 0.015s\n",
      "[239/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63645, val loss: 0.63835, in 0.016s\n",
      "[240/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63644, val loss: 0.63834, in 0.015s\n",
      "[241/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63643, val loss: 0.63834, in 0.015s\n",
      "[242/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63643, val loss: 0.63834, in 0.016s\n",
      "[243/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.63642, val loss: 0.63833, in 0.017s\n",
      "[244/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63641, val loss: 0.63833, in 0.015s\n",
      "[245/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63640, val loss: 0.63831, in 0.014s\n",
      "[246/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63639, val loss: 0.63831, in 0.015s\n",
      "[247/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63638, val loss: 0.63830, in 0.015s\n",
      "[248/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63638, val loss: 0.63830, in 0.013s\n",
      "[249/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63637, val loss: 0.63830, in 0.015s\n",
      "[250/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63637, val loss: 0.63829, in 0.015s\n",
      "[251/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63636, val loss: 0.63829, in 0.015s\n",
      "[252/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63635, val loss: 0.63828, in 0.016s\n",
      "[253/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63634, val loss: 0.63828, in 0.015s\n",
      "[254/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63634, val loss: 0.63828, in 0.039s\n",
      "[255/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63633, val loss: 0.63828, in 0.020s\n",
      "[256/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63632, val loss: 0.63829, in 0.013s\n",
      "[257/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63632, val loss: 0.63828, in 0.013s\n",
      "[258/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63631, val loss: 0.63828, in 0.013s\n",
      "[259/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63631, val loss: 0.63828, in 0.014s\n",
      "[260/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.63630, val loss: 0.63827, in 0.016s\n",
      "[261/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63630, val loss: 0.63827, in 0.013s\n",
      "[262/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63629, val loss: 0.63828, in 0.014s\n",
      "[263/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63629, val loss: 0.63828, in 0.014s\n",
      "[264/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63628, val loss: 0.63827, in 0.014s\n",
      "[265/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63628, val loss: 0.63827, in 0.015s\n",
      "[266/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63627, val loss: 0.63827, in 0.014s\n",
      "[267/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63627, val loss: 0.63827, in 0.013s\n",
      "[268/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63627, val loss: 0.63827, in 0.014s\n",
      "[269/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63626, val loss: 0.63827, in 0.015s\n",
      "[270/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63625, val loss: 0.63827, in 0.024s\n",
      "[271/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.63625, val loss: 0.63827, in 0.015s\n",
      "[272/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63624, val loss: 0.63826, in 0.014s\n",
      "[273/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63624, val loss: 0.63826, in 0.014s\n",
      "[274/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63624, val loss: 0.63826, in 0.015s\n",
      "[275/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63623, val loss: 0.63825, in 0.014s\n",
      "[276/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63622, val loss: 0.63825, in 0.013s\n",
      "[277/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63622, val loss: 0.63824, in 0.015s\n",
      "[278/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63621, val loss: 0.63824, in 0.016s\n",
      "[279/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63621, val loss: 0.63824, in 0.020s\n",
      "[280/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63620, val loss: 0.63824, in 0.013s\n",
      "[281/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63619, val loss: 0.63823, in 0.014s\n",
      "[282/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63619, val loss: 0.63823, in 0.014s\n",
      "[283/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63618, val loss: 0.63823, in 0.013s\n",
      "[284/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63618, val loss: 0.63822, in 0.013s\n",
      "[285/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63618, val loss: 0.63822, in 0.014s\n",
      "[286/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63617, val loss: 0.63822, in 0.014s\n",
      "[287/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63617, val loss: 0.63822, in 0.014s\n",
      "[288/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63616, val loss: 0.63822, in 0.014s\n",
      "[289/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63616, val loss: 0.63822, in 0.015s\n",
      "[290/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63615, val loss: 0.63822, in 0.013s\n",
      "[291/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63615, val loss: 0.63821, in 0.014s\n",
      "[292/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63615, val loss: 0.63821, in 0.014s\n",
      "[293/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63614, val loss: 0.63822, in 0.014s\n",
      "[294/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63614, val loss: 0.63822, in 0.015s\n",
      "[295/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63613, val loss: 0.63822, in 0.015s\n",
      "[296/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63613, val loss: 0.63821, in 0.015s\n",
      "[297/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63612, val loss: 0.63821, in 0.014s\n",
      "[298/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63612, val loss: 0.63822, in 0.014s\n",
      "[299/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63611, val loss: 0.63822, in 0.014s\n",
      "[300/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63611, val loss: 0.63822, in 0.015s\n",
      "[301/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63610, val loss: 0.63821, in 0.013s\n",
      "[302/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63610, val loss: 0.63821, in 0.015s\n",
      "[303/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63609, val loss: 0.63821, in 0.013s\n",
      "[304/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63609, val loss: 0.63820, in 0.013s\n",
      "[305/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63609, val loss: 0.63820, in 0.014s\n",
      "[306/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63608, val loss: 0.63821, in 0.016s\n",
      "[307/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63608, val loss: 0.63820, in 0.015s\n",
      "[308/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.63607, val loss: 0.63820, in 0.015s\n",
      "[309/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63607, val loss: 0.63819, in 0.014s\n",
      "[310/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63607, val loss: 0.63819, in 0.014s\n",
      "[311/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63606, val loss: 0.63819, in 0.016s\n",
      "[312/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63606, val loss: 0.63819, in 0.014s\n",
      "[313/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63606, val loss: 0.63819, in 0.014s\n",
      "[314/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63605, val loss: 0.63818, in 0.014s\n",
      "[315/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63605, val loss: 0.63818, in 0.014s\n",
      "[316/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63604, val loss: 0.63818, in 0.015s\n",
      "[317/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63604, val loss: 0.63818, in 0.014s\n",
      "[318/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63604, val loss: 0.63818, in 0.014s\n",
      "[319/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63603, val loss: 0.63818, in 0.015s\n",
      "[320/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63603, val loss: 0.63818, in 0.016s\n",
      "[321/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.63603, val loss: 0.63818, in 0.015s\n",
      "[322/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63603, val loss: 0.63818, in 0.014s\n",
      "[323/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63602, val loss: 0.63818, in 0.016s\n",
      "[324/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63602, val loss: 0.63818, in 0.014s\n",
      "[325/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63602, val loss: 0.63818, in 0.015s\n",
      "[326/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63601, val loss: 0.63818, in 0.015s\n",
      "[327/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63601, val loss: 0.63818, in 0.016s\n",
      "[328/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63601, val loss: 0.63818, in 0.015s\n",
      "[329/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63601, val loss: 0.63818, in 0.015s\n",
      "[330/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63600, val loss: 0.63818, in 0.014s\n",
      "[331/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63600, val loss: 0.63818, in 0.014s\n",
      "[332/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.63600, val loss: 0.63818, in 0.013s\n",
      "[333/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63600, val loss: 0.63817, in 0.014s\n",
      "[334/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.63600, val loss: 0.63818, in 0.021s\n",
      "[335/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63599, val loss: 0.63818, in 0.016s\n",
      "[336/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63599, val loss: 0.63817, in 0.015s\n",
      "[337/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63599, val loss: 0.63817, in 0.015s\n",
      "[338/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63599, val loss: 0.63817, in 0.027s\n",
      "[339/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63598, val loss: 0.63817, in 0.016s\n",
      "[340/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63598, val loss: 0.63817, in 0.015s\n",
      "[341/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63598, val loss: 0.63817, in 0.016s\n",
      "[342/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63597, val loss: 0.63817, in 0.015s\n",
      "[343/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63597, val loss: 0.63817, in 0.016s\n",
      "[344/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63597, val loss: 0.63817, in 0.015s\n",
      "[345/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63597, val loss: 0.63816, in 0.015s\n",
      "[346/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63596, val loss: 0.63816, in 0.015s\n",
      "[347/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63596, val loss: 0.63816, in 0.016s\n",
      "[348/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63596, val loss: 0.63816, in 0.015s\n",
      "[349/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63596, val loss: 0.63816, in 0.014s\n",
      "[350/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63596, val loss: 0.63816, in 0.015s\n",
      "[351/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63595, val loss: 0.63816, in 0.016s\n",
      "[352/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63595, val loss: 0.63816, in 0.014s\n",
      "[353/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63595, val loss: 0.63816, in 0.017s\n",
      "[354/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63594, val loss: 0.63816, in 0.015s\n",
      "[355/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63594, val loss: 0.63816, in 0.015s\n",
      "[356/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63594, val loss: 0.63817, in 0.014s\n",
      "[357/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63594, val loss: 0.63816, in 0.015s\n",
      "[358/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63593, val loss: 0.63816, in 0.016s\n",
      "[359/10000] 1 tree, 31 leaves, max depth = 17, train loss: 0.63593, val loss: 0.63816, in 0.014s\n",
      "[360/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63593, val loss: 0.63816, in 0.038s\n",
      "[361/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63593, val loss: 0.63816, in 0.022s\n",
      "[362/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63592, val loss: 0.63816, in 0.014s\n",
      "[363/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63592, val loss: 0.63816, in 0.016s\n",
      "[364/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63592, val loss: 0.63816, in 0.015s\n",
      "[365/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63592, val loss: 0.63816, in 0.015s\n",
      "[366/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63591, val loss: 0.63815, in 0.014s\n",
      "[367/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63591, val loss: 0.63815, in 0.015s\n",
      "[368/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63591, val loss: 0.63815, in 0.015s\n",
      "[369/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63591, val loss: 0.63815, in 0.015s\n",
      "[370/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.63591, val loss: 0.63815, in 0.016s\n",
      "[371/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63590, val loss: 0.63815, in 0.017s\n",
      "[372/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.63590, val loss: 0.63815, in 0.015s\n",
      "[373/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.63590, val loss: 0.63815, in 0.016s\n",
      "[374/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63590, val loss: 0.63815, in 0.013s\n",
      "[375/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63590, val loss: 0.63815, in 0.016s\n",
      "[376/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63590, val loss: 0.63815, in 0.016s\n",
      "[377/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63589, val loss: 0.63815, in 0.016s\n",
      "[378/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63589, val loss: 0.63815, in 0.015s\n",
      "[379/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63589, val loss: 0.63815, in 0.016s\n",
      "[380/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.63589, val loss: 0.63815, in 0.015s\n",
      "[381/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63589, val loss: 0.63815, in 0.016s\n",
      "Fit 381 trees in 6.228 s, (11811 total leaves)\n",
      "Time spent computing histograms: 1.228s\n",
      "Time spent finding best splits:  0.321s\n",
      "Time spent applying splits:      0.866s\n",
      "Time spent predicting:           0.162s\n",
      "Accuracy Score: 0.6304045037937449\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.63      0.63     51335\n",
      "         1.0       0.63      0.63      0.63     51334\n",
      "\n",
      "    accuracy                           0.63    102669\n",
      "   macro avg       0.63      0.63      0.63    102669\n",
      "weighted avg       0.63      0.63      0.63    102669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# Instantiate the model with default hyperparameters\n",
    "gbc = HistGradientBoostingClassifier(max_iter = 10000, verbose=1, random_state=0)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(balanced_df.drop(columns=['ARR_DEL15']), balanced_df['ARR_DEL15'], test_size=0.2, stratify=balanced_df['ARR_DEL15'], random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 46 candidates, totalling 230 fits\n",
      "Best depth: 14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': [i for i in range(1,47 ,1)]}\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, verbose=3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best depth found by the grid search\n",
    "print(\"Best depth:\", grid_search.best_params_['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Depth:  14\n",
      "Number of leaves:  7850\n",
      "Accuracy: 0.6537611158187964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.68      0.66     51335\n",
      "         1.0       0.66      0.63      0.64     51334\n",
      "\n",
      "    accuracy                           0.65    102669\n",
      "   macro avg       0.65      0.65      0.65    102669\n",
      "weighted avg       0.65      0.65      0.65    102669\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, PrecisionRecallDisplay\n",
    "\n",
    "# Train the decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth = 14)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "  \n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Tree Depth: ', clf.get_depth())\n",
    "print('Number of leaves: ', clf.get_n_leaves())\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# print the report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "display = PrecisionRecallDisplay.from_predictions(y_test, y_pred)\n",
    "_ = display.ax_.set_title(\"Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "feature_importances = pd.Series(clf.feature_importances_, index=X_train.columns)\n",
    "feature_importances.sort_values().plot(kind='barh')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 500\n",
      "building tree 2 of 500\n",
      "building tree 3 of 500\n",
      "building tree 4 of 500\n",
      "building tree 5 of 500\n",
      "building tree 6 of 500\n",
      "building tree 7 of 500\n",
      "building tree 8 of 500\n",
      "building tree 9 of 500\n",
      "building tree 10 of 500\n",
      "building tree 11 of 500\n",
      "building tree 12 of 500\n",
      "building tree 13 of 500\n",
      "building tree 14 of 500\n",
      "building tree 15 of 500\n",
      "building tree 16 of 500\n",
      "building tree 17 of 500\n",
      "building tree 18 of 500\n",
      "building tree 19 of 500\n",
      "building tree 20 of 500\n",
      "building tree 21 of 500\n",
      "building tree 22 of 500\n",
      "building tree 23 of 500\n",
      "building tree 24 of 500\n",
      "building tree 25 of 500\n",
      "building tree 26 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 27 of 500\n",
      "building tree 28 of 500\n",
      "building tree 29 of 500\n",
      "building tree 30 of 500\n",
      "building tree 31 of 500\n",
      "building tree 32 of 500\n",
      "building tree 33 of 500\n",
      "building tree 34 of 500\n",
      "building tree 35 of 500\n",
      "building tree 36 of 500\n",
      "building tree 37 of 500\n",
      "building tree 38 of 500\n",
      "building tree 39 of 500\n",
      "building tree 40 of 500\n",
      "building tree 41 of 500\n",
      "building tree 42 of 500\n",
      "building tree 43 of 500\n",
      "building tree 44 of 500\n",
      "building tree 45 of 500\n",
      "building tree 46 of 500\n",
      "building tree 47 of 500\n",
      "building tree 48 of 500\n",
      "building tree 49 of 500\n",
      "building tree 50 of 500\n",
      "building tree 51 of 500\n",
      "building tree 52 of 500\n",
      "building tree 53 of 500\n",
      "building tree 54 of 500\n",
      "building tree 55 of 500\n",
      "building tree 56 of 500\n",
      "building tree 57 of 500\n",
      "building tree 58 of 500\n",
      "building tree 59 of 500\n",
      "building tree 60 of 500\n",
      "building tree 61 of 500\n",
      "building tree 62 of 500\n",
      "building tree 63 of 500\n",
      "building tree 64 of 500\n",
      "building tree 65 of 500\n",
      "building tree 66 of 500\n",
      "building tree 67 of 500\n",
      "building tree 68 of 500\n",
      "building tree 69 of 500\n",
      "building tree 70 of 500\n",
      "building tree 71 of 500\n",
      "building tree 72 of 500\n",
      "building tree 73 of 500\n",
      "building tree 74 of 500\n",
      "building tree 75 of 500\n",
      "building tree 76 of 500\n",
      "building tree 77 of 500\n",
      "building tree 78 of 500\n",
      "building tree 79 of 500\n",
      "building tree 80 of 500\n",
      "building tree 81 of 500\n",
      "building tree 82 of 500\n",
      "building tree 83 of 500\n",
      "building tree 84 of 500\n",
      "building tree 85 of 500\n",
      "building tree 86 of 500\n",
      "building tree 87 of 500\n",
      "building tree 88 of 500\n",
      "building tree 89 of 500\n",
      "building tree 90 of 500\n",
      "building tree 91 of 500\n",
      "building tree 92 of 500\n",
      "building tree 93 of 500\n",
      "building tree 94 of 500\n",
      "building tree 95 of 500\n",
      "building tree 96 of 500\n",
      "building tree 97 of 500\n",
      "building tree 98 of 500\n",
      "building tree 99 of 500\n",
      "building tree 100 of 500\n",
      "building tree 101 of 500\n",
      "building tree 102 of 500\n",
      "building tree 103 of 500\n",
      "building tree 104 of 500\n",
      "building tree 105 of 500\n",
      "building tree 106 of 500\n",
      "building tree 107 of 500\n",
      "building tree 108 of 500\n",
      "building tree 109 of 500\n",
      "building tree 110 of 500\n",
      "building tree 111 of 500\n",
      "building tree 112 of 500\n",
      "building tree 113 of 500\n",
      "building tree 114 of 500\n",
      "building tree 115 of 500\n",
      "building tree 116 of 500\n",
      "building tree 117 of 500\n",
      "building tree 118 of 500\n",
      "building tree 119 of 500\n",
      "building tree 120 of 500\n",
      "building tree 121 of 500\n",
      "building tree 122 of 500\n",
      "building tree 123 of 500\n",
      "building tree 124 of 500\n",
      "building tree 125 of 500\n",
      "building tree 126 of 500\n",
      "building tree 127 of 500\n",
      "building tree 128 of 500\n",
      "building tree 129 of 500\n",
      "building tree 130 of 500\n",
      "building tree 131 of 500\n",
      "building tree 132 of 500\n",
      "building tree 133 of 500\n",
      "building tree 134 of 500\n",
      "building tree 135 of 500\n",
      "building tree 136 of 500\n",
      "building tree 137 of 500\n",
      "building tree 138 of 500\n",
      "building tree 139 of 500\n",
      "building tree 140 of 500\n",
      "building tree 141 of 500\n",
      "building tree 142 of 500\n",
      "building tree 143 of 500\n",
      "building tree 144 of 500\n",
      "building tree 145 of 500\n",
      "building tree 146 of 500\n",
      "building tree 147 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   18.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 148 of 500\n",
      "building tree 149 of 500\n",
      "building tree 150 of 500\n",
      "building tree 151 of 500\n",
      "building tree 152 of 500\n",
      "building tree 153 of 500\n",
      "building tree 154 of 500\n",
      "building tree 155 of 500\n",
      "building tree 156 of 500\n",
      "building tree 157 of 500\n",
      "building tree 158 of 500\n",
      "building tree 159 of 500\n",
      "building tree 160 of 500\n",
      "building tree 161 of 500\n",
      "building tree 162 of 500\n",
      "building tree 163 of 500\n",
      "building tree 164 of 500\n",
      "building tree 165 of 500\n",
      "building tree 166 of 500\n",
      "building tree 167 of 500\n",
      "building tree 168 of 500\n",
      "building tree 169 of 500\n",
      "building tree 170 of 500\n",
      "building tree 171 of 500\n",
      "building tree 172 of 500\n",
      "building tree 173 of 500\n",
      "building tree 174 of 500\n",
      "building tree 175 of 500\n",
      "building tree 176 of 500\n",
      "building tree 177 of 500\n",
      "building tree 178 of 500\n",
      "building tree 179 of 500\n",
      "building tree 180 of 500\n",
      "building tree 181 of 500\n",
      "building tree 182 of 500\n",
      "building tree 183 of 500\n",
      "building tree 184 of 500\n",
      "building tree 185 of 500\n",
      "building tree 186 of 500\n",
      "building tree 187 of 500\n",
      "building tree 188 of 500\n",
      "building tree 189 of 500\n",
      "building tree 190 of 500\n",
      "building tree 191 of 500\n",
      "building tree 192 of 500\n",
      "building tree 193 of 500\n",
      "building tree 194 of 500\n",
      "building tree 195 of 500\n",
      "building tree 196 of 500\n",
      "building tree 197 of 500\n",
      "building tree 198 of 500\n",
      "building tree 199 of 500\n",
      "building tree 200 of 500\n",
      "building tree 201 of 500\n",
      "building tree 202 of 500\n",
      "building tree 203 of 500\n",
      "building tree 204 of 500\n",
      "building tree 205 of 500\n",
      "building tree 206 of 500\n",
      "building tree 207 of 500\n",
      "building tree 208 of 500\n",
      "building tree 209 of 500\n",
      "building tree 210 of 500\n",
      "building tree 211 of 500\n",
      "building tree 212 of 500\n",
      "building tree 213 of 500\n",
      "building tree 214 of 500\n",
      "building tree 215 of 500\n",
      "building tree 216 of 500\n",
      "building tree 217 of 500\n",
      "building tree 218 of 500\n",
      "building tree 219 of 500\n",
      "building tree 220 of 500\n",
      "building tree 221 of 500\n",
      "building tree 222 of 500\n",
      "building tree 223 of 500\n",
      "building tree 224 of 500\n",
      "building tree 225 of 500\n",
      "building tree 226 of 500\n",
      "building tree 227 of 500\n",
      "building tree 228 of 500\n",
      "building tree 229 of 500\n",
      "building tree 230 of 500\n",
      "building tree 231 of 500\n",
      "building tree 232 of 500\n",
      "building tree 233 of 500\n",
      "building tree 234 of 500\n",
      "building tree 235 of 500\n",
      "building tree 236 of 500\n",
      "building tree 237 of 500\n",
      "building tree 238 of 500\n",
      "building tree 239 of 500\n",
      "building tree 240 of 500\n",
      "building tree 241 of 500\n",
      "building tree 242 of 500\n",
      "building tree 243 of 500\n",
      "building tree 244 of 500\n",
      "building tree 245 of 500\n",
      "building tree 246 of 500\n",
      "building tree 247 of 500\n",
      "building tree 248 of 500\n",
      "building tree 249 of 500\n",
      "building tree 250 of 500\n",
      "building tree 251 of 500\n",
      "building tree 252 of 500\n",
      "building tree 253 of 500\n",
      "building tree 254 of 500\n",
      "building tree 255 of 500\n",
      "building tree 256 of 500\n",
      "building tree 257 of 500\n",
      "building tree 258 of 500\n",
      "building tree 259 of 500\n",
      "building tree 260 of 500\n",
      "building tree 261 of 500\n",
      "building tree 262 of 500\n",
      "building tree 263 of 500\n",
      "building tree 264 of 500\n",
      "building tree 265 of 500\n",
      "building tree 266 of 500\n",
      "building tree 267 of 500\n",
      "building tree 268 of 500\n",
      "building tree 269 of 500\n",
      "building tree 270 of 500\n",
      "building tree 271 of 500\n",
      "building tree 272 of 500\n",
      "building tree 273 of 500\n",
      "building tree 274 of 500\n",
      "building tree 275 of 500\n",
      "building tree 276 of 500\n",
      "building tree 277 of 500\n",
      "building tree 278 of 500\n",
      "building tree 279 of 500\n",
      "building tree 280 of 500\n",
      "building tree 281 of 500\n",
      "building tree 282 of 500\n",
      "building tree 283 of 500\n",
      "building tree 284 of 500\n",
      "building tree 285 of 500\n",
      "building tree 286 of 500\n",
      "building tree 287 of 500\n",
      "building tree 288 of 500\n",
      "building tree 289 of 500\n",
      "building tree 290 of 500\n",
      "building tree 291 of 500\n",
      "building tree 292 of 500\n",
      "building tree 293 of 500\n",
      "building tree 294 of 500\n",
      "building tree 295 of 500\n",
      "building tree 296 of 500\n",
      "building tree 297 of 500\n",
      "building tree 298 of 500\n",
      "building tree 299 of 500\n",
      "building tree 300 of 500\n",
      "building tree 301 of 500\n",
      "building tree 302 of 500\n",
      "building tree 303 of 500\n",
      "building tree 304 of 500\n",
      "building tree 305 of 500\n",
      "building tree 306 of 500\n",
      "building tree 307 of 500\n",
      "building tree 308 of 500\n",
      "building tree 309 of 500\n",
      "building tree 310 of 500\n",
      "building tree 311 of 500\n",
      "building tree 312 of 500\n",
      "building tree 313 of 500\n",
      "building tree 314 of 500\n",
      "building tree 315 of 500\n",
      "building tree 316 of 500\n",
      "building tree 317 of 500\n",
      "building tree 318 of 500\n",
      "building tree 319 of 500\n",
      "building tree 320 of 500\n",
      "building tree 321 of 500building tree 322 of 500\n",
      "\n",
      "building tree 323 of 500\n",
      "building tree 324 of 500\n",
      "building tree 325 of 500\n",
      "building tree 326 of 500\n",
      "building tree 327 of 500\n",
      "building tree 328 of 500\n",
      "building tree 329 of 500\n",
      "building tree 330 of 500\n",
      "building tree 331 of 500\n",
      "building tree 332 of 500\n",
      "building tree 333 of 500\n",
      "building tree 334 of 500\n",
      "building tree 335 of 500\n",
      "building tree 336 of 500\n",
      "building tree 337 of 500\n",
      "building tree 338 of 500\n",
      "building tree 339 of 500\n",
      "building tree 340 of 500\n",
      "building tree 341 of 500\n",
      "building tree 342 of 500\n",
      "building tree 343 of 500\n",
      "building tree 344 of 500\n",
      "building tree 345 of 500\n",
      "building tree 346 of 500\n",
      "building tree 347 of 500\n",
      "building tree 348 of 500\n",
      "building tree 349 of 500\n",
      "building tree 350 of 500\n",
      "building tree 351 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   45.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 352 of 500\n",
      "building tree 353 of 500\n",
      "building tree 354 of 500\n",
      "building tree 355 of 500\n",
      "building tree 356 of 500\n",
      "building tree 357 of 500\n",
      "building tree 358 of 500\n",
      "building tree 359 of 500\n",
      "building tree 360 of 500\n",
      "building tree 361 of 500\n",
      "building tree 362 of 500\n",
      "building tree 363 of 500\n",
      "building tree 364 of 500\n",
      "building tree 365 of 500\n",
      "building tree 366 of 500\n",
      "building tree 367 of 500\n",
      "building tree 368 of 500\n",
      "building tree 369 of 500\n",
      "building tree 370 of 500\n",
      "building tree 371 of 500\n",
      "building tree 372 of 500\n",
      "building tree 373 of 500\n",
      "building tree 374 of 500\n",
      "building tree 375 of 500\n",
      "building tree 376 of 500\n",
      "building tree 377 of 500\n",
      "building tree 378 of 500\n",
      "building tree 379 of 500\n",
      "building tree 380 of 500\n",
      "building tree 381 of 500\n",
      "building tree 382 of 500\n",
      "building tree 383 of 500\n",
      "building tree 384 of 500\n",
      "building tree 385 of 500\n",
      "building tree 386 of 500\n",
      "building tree 387 of 500\n",
      "building tree 388 of 500\n",
      "building tree 389 of 500\n",
      "building tree 390 of 500\n",
      "building tree 391 of 500\n",
      "building tree 392 of 500\n",
      "building tree 393 of 500\n",
      "building tree 394 of 500\n",
      "building tree 395 of 500\n",
      "building tree 396 of 500\n",
      "building tree 397 of 500\n",
      "building tree 398 of 500\n",
      "building tree 399 of 500\n",
      "building tree 400 of 500\n",
      "building tree 401 of 500\n",
      "building tree 402 of 500\n",
      "building tree 403 of 500\n",
      "building tree 404 of 500\n",
      "building tree 405 of 500\n",
      "building tree 406 of 500\n",
      "building tree 407 of 500\n",
      "building tree 408 of 500\n",
      "building tree 409 of 500\n",
      "building tree 410 of 500\n",
      "building tree 411 of 500\n",
      "building tree 412 of 500\n",
      "building tree 413 of 500\n",
      "building tree 414 of 500\n",
      "building tree 415 of 500\n",
      "building tree 416 of 500\n",
      "building tree 417 of 500\n",
      "building tree 418 of 500\n",
      "building tree 419 of 500\n",
      "building tree 420 of 500\n",
      "building tree 421 of 500\n",
      "building tree 422 of 500\n",
      "building tree 423 of 500\n",
      "building tree 424 of 500\n",
      "building tree 425 of 500\n",
      "building tree 426 of 500\n",
      "building tree 427 of 500\n",
      "building tree 428 of 500\n",
      "building tree 429 of 500\n",
      "building tree 430 of 500\n",
      "building tree 431 of 500\n",
      "building tree 432 of 500\n",
      "building tree 433 of 500\n",
      "building tree 434 of 500\n",
      "building tree 435 of 500\n",
      "building tree 436 of 500\n",
      "building tree 437 of 500\n",
      "building tree 438 of 500\n",
      "building tree 439 of 500\n",
      "building tree 440 of 500\n",
      "building tree 441 of 500\n",
      "building tree 442 of 500\n",
      "building tree 443 of 500\n",
      "building tree 444 of 500\n",
      "building tree 445 of 500\n",
      "building tree 446 of 500\n",
      "building tree 447 of 500\n",
      "building tree 448 of 500\n",
      "building tree 449 of 500\n",
      "building tree 450 of 500\n",
      "building tree 451 of 500\n",
      "building tree 452 of 500\n",
      "building tree 453 of 500\n",
      "building tree 454 of 500\n",
      "building tree 455 of 500\n",
      "building tree 456 of 500\n",
      "building tree 457 of 500\n",
      "building tree 458 of 500\n",
      "building tree 459 of 500\n",
      "building tree 460 of 500\n",
      "building tree 461 of 500\n",
      "building tree 462 of 500\n",
      "building tree 463 of 500\n",
      "building tree 464 of 500\n",
      "building tree 465 of 500\n",
      "building tree 466 of 500\n",
      "building tree 467 of 500\n",
      "building tree 468 of 500\n",
      "building tree 469 of 500\n",
      "building tree 470 of 500\n",
      "building tree 471 of 500\n",
      "building tree 472 of 500\n",
      "building tree 473 of 500\n",
      "building tree 474 of 500\n",
      "building tree 475 of 500\n",
      "building tree 476 of 500\n",
      "building tree 477 of 500\n",
      "building tree 478 of 500\n",
      "building tree 479 of 500\n",
      "building tree 480 of 500\n",
      "building tree 481 of 500\n",
      "building tree 482 of 500\n",
      "building tree 483 of 500\n",
      "building tree 484 of 500\n",
      "building tree 485 of 500\n",
      "building tree 486 of 500\n",
      "building tree 487 of 500\n",
      "building tree 488 of 500\n",
      "building tree 489 of 500\n",
      "building tree 490 of 500\n",
      "building tree 491 of 500\n",
      "building tree 492 of 500\n",
      "building tree 493 of 500\n",
      "building tree 494 of 500\n",
      "building tree 495 of 500\n",
      "building tree 496 of 500\n",
      "building tree 497 of 500\n",
      "building tree 498 of 500\n",
      "building tree 499 of 500\n",
      "building tree 500 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 130 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=16)]: Done 333 tasks      | elapsed:    2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7035716720723879\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.72      0.71     51335\n",
      "         1.0       0.71      0.68      0.70     51334\n",
      "\n",
      "    accuracy                           0.70    102669\n",
      "   macro avg       0.70      0.70      0.70    102669\n",
      "weighted avg       0.70      0.70      0.70    102669\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 500 out of 500 | elapsed:    3.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a random forest classifier object\n",
    "rf = RandomForestClassifier(n_estimators = 500, n_jobs=-1, verbose=2, random_state=0)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosted tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.062 GB of training data: 0.341 s\n",
      "Binning 0.007 GB of validation data: 0.004 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.68514, val loss: 0.68505, in 0.027s\n",
      "[2/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.67861, val loss: 0.67850, in 0.025s\n",
      "[3/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.67290, val loss: 0.67268, in 0.024s\n",
      "[4/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.66815, val loss: 0.66787, in 0.025s\n",
      "[5/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.66382, val loss: 0.66352, in 0.024s\n",
      "[6/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.66027, val loss: 0.65998, in 0.026s\n",
      "[7/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.65722, val loss: 0.65691, in 0.024s\n",
      "[8/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.65456, val loss: 0.65419, in 0.026s\n",
      "[9/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.65187, val loss: 0.65145, in 0.024s\n",
      "[10/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64972, val loss: 0.64918, in 0.027s\n",
      "[11/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.64765, val loss: 0.64709, in 0.029s\n",
      "[12/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.64576, val loss: 0.64523, in 0.025s\n",
      "[13/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.64401, val loss: 0.64345, in 0.027s\n",
      "[14/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.64215, val loss: 0.64159, in 0.025s\n",
      "[15/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.64088, val loss: 0.64031, in 0.026s\n",
      "[16/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63940, val loss: 0.63887, in 0.027s\n",
      "[17/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63790, val loss: 0.63734, in 0.027s\n",
      "[18/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63669, val loss: 0.63604, in 0.042s\n",
      "[19/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63535, val loss: 0.63475, in 0.027s\n",
      "[20/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.63436, val loss: 0.63374, in 0.023s\n",
      "[21/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.63316, val loss: 0.63251, in 0.037s\n",
      "[22/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63216, val loss: 0.63158, in 0.024s\n",
      "[23/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.63134, val loss: 0.63075, in 0.025s\n",
      "[24/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63017, val loss: 0.62962, in 0.024s\n",
      "[25/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.62933, val loss: 0.62888, in 0.025s\n",
      "[26/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.62861, val loss: 0.62817, in 0.022s\n",
      "[27/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.62799, val loss: 0.62761, in 0.024s\n",
      "[28/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.62720, val loss: 0.62690, in 0.022s\n",
      "[29/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.62652, val loss: 0.62620, in 0.025s\n",
      "[30/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.62588, val loss: 0.62556, in 0.022s\n",
      "[31/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.62512, val loss: 0.62484, in 0.027s\n",
      "[32/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.62446, val loss: 0.62423, in 0.021s\n",
      "[33/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.62378, val loss: 0.62361, in 0.022s\n",
      "[34/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.62328, val loss: 0.62314, in 0.024s\n",
      "[35/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.62255, val loss: 0.62245, in 0.025s\n",
      "[36/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.62204, val loss: 0.62197, in 0.023s\n",
      "[37/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.62144, val loss: 0.62148, in 0.022s\n",
      "[38/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.62089, val loss: 0.62089, in 0.025s\n",
      "[39/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.62025, val loss: 0.62023, in 0.022s\n",
      "[40/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.61963, val loss: 0.61962, in 0.024s\n",
      "[41/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.61910, val loss: 0.61914, in 0.022s\n",
      "[42/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.61871, val loss: 0.61876, in 0.024s\n",
      "[43/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.61833, val loss: 0.61842, in 0.025s\n",
      "[44/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.61776, val loss: 0.61789, in 0.025s\n",
      "[45/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.61731, val loss: 0.61753, in 0.021s\n",
      "[46/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.61670, val loss: 0.61702, in 0.022s\n",
      "[47/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.61608, val loss: 0.61647, in 0.021s\n",
      "[48/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.61555, val loss: 0.61589, in 0.022s\n",
      "[49/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.61504, val loss: 0.61542, in 0.022s\n",
      "[50/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.61471, val loss: 0.61517, in 0.020s\n",
      "[51/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.61419, val loss: 0.61471, in 0.024s\n",
      "[52/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.61382, val loss: 0.61439, in 0.022s\n",
      "[53/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.61336, val loss: 0.61400, in 0.023s\n",
      "[54/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.61303, val loss: 0.61370, in 0.022s\n",
      "[55/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.61254, val loss: 0.61324, in 0.022s\n",
      "[56/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.61209, val loss: 0.61278, in 0.024s\n",
      "[57/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.61164, val loss: 0.61242, in 0.021s\n",
      "[58/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.61138, val loss: 0.61219, in 0.021s\n",
      "[59/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.61109, val loss: 0.61191, in 0.023s\n",
      "[60/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.61065, val loss: 0.61145, in 0.027s\n",
      "[61/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.61024, val loss: 0.61106, in 0.032s\n",
      "[62/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60989, val loss: 0.61080, in 0.020s\n",
      "[63/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.60957, val loss: 0.61046, in 0.020s\n",
      "[64/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60923, val loss: 0.61018, in 0.020s\n",
      "[65/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60890, val loss: 0.60986, in 0.023s\n",
      "[66/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.60862, val loss: 0.60968, in 0.021s\n",
      "[67/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.60833, val loss: 0.60945, in 0.023s\n",
      "[68/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60794, val loss: 0.60912, in 0.023s\n",
      "[69/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.60769, val loss: 0.60890, in 0.022s\n",
      "[70/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.60745, val loss: 0.60874, in 0.022s\n",
      "[71/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.60719, val loss: 0.60852, in 0.028s\n",
      "[72/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.60671, val loss: 0.60814, in 0.027s\n",
      "[73/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60651, val loss: 0.60798, in 0.024s\n",
      "[74/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.60628, val loss: 0.60781, in 0.024s\n",
      "[75/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.60606, val loss: 0.60766, in 0.022s\n",
      "[76/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.60569, val loss: 0.60735, in 0.025s\n",
      "[77/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60549, val loss: 0.60717, in 0.021s\n",
      "[78/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60528, val loss: 0.60704, in 0.024s\n",
      "[79/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.60512, val loss: 0.60691, in 0.023s\n",
      "[80/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60482, val loss: 0.60666, in 0.026s\n",
      "[81/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.60461, val loss: 0.60648, in 0.021s\n",
      "[82/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.60447, val loss: 0.60632, in 0.020s\n",
      "[83/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60433, val loss: 0.60624, in 0.020s\n",
      "[84/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60409, val loss: 0.60603, in 0.019s\n",
      "[85/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.60384, val loss: 0.60584, in 0.023s\n",
      "[86/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.60354, val loss: 0.60559, in 0.022s\n",
      "[87/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.60325, val loss: 0.60540, in 0.023s\n",
      "[88/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.60306, val loss: 0.60526, in 0.022s\n",
      "[89/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.60285, val loss: 0.60509, in 0.022s\n",
      "[90/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.60262, val loss: 0.60490, in 0.022s\n",
      "[91/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.60241, val loss: 0.60472, in 0.024s\n",
      "[92/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.60213, val loss: 0.60445, in 0.020s\n",
      "[93/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60183, val loss: 0.60418, in 0.024s\n",
      "[94/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.60168, val loss: 0.60404, in 0.021s\n",
      "[95/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.60148, val loss: 0.60387, in 0.023s\n",
      "[96/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.60135, val loss: 0.60381, in 0.020s\n",
      "[97/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.60119, val loss: 0.60370, in 0.021s\n",
      "[98/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.60107, val loss: 0.60362, in 0.022s\n",
      "[99/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.60074, val loss: 0.60325, in 0.026s\n",
      "[100/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.60060, val loss: 0.60318, in 0.026s\n",
      "[101/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.60045, val loss: 0.60307, in 0.022s\n",
      "[102/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.60028, val loss: 0.60293, in 0.022s\n",
      "[103/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.60016, val loss: 0.60286, in 0.020s\n",
      "[104/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.59999, val loss: 0.60276, in 0.020s\n",
      "[105/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59975, val loss: 0.60262, in 0.038s\n",
      "[106/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59940, val loss: 0.60237, in 0.024s\n",
      "[107/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59925, val loss: 0.60225, in 0.021s\n",
      "[108/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59899, val loss: 0.60206, in 0.025s\n",
      "[109/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.59871, val loss: 0.60182, in 0.023s\n",
      "[110/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59853, val loss: 0.60172, in 0.020s\n",
      "[111/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59832, val loss: 0.60155, in 0.030s\n",
      "[112/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.59805, val loss: 0.60130, in 0.021s\n",
      "[113/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.59790, val loss: 0.60118, in 0.019s\n",
      "[114/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59774, val loss: 0.60103, in 0.019s\n",
      "[115/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.59756, val loss: 0.60089, in 0.019s\n",
      "[116/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59737, val loss: 0.60077, in 0.022s\n",
      "[117/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59718, val loss: 0.60060, in 0.018s\n",
      "[118/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.59692, val loss: 0.60038, in 0.022s\n",
      "[119/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.59681, val loss: 0.60033, in 0.019s\n",
      "[120/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.59664, val loss: 0.60020, in 0.020s\n",
      "[121/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59648, val loss: 0.60006, in 0.021s\n",
      "[122/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.59630, val loss: 0.59993, in 0.019s\n",
      "[123/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59613, val loss: 0.59983, in 0.021s\n",
      "[124/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59589, val loss: 0.59961, in 0.020s\n",
      "[125/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59574, val loss: 0.59949, in 0.018s\n",
      "[126/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59546, val loss: 0.59924, in 0.021s\n",
      "[127/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59536, val loss: 0.59919, in 0.020s\n",
      "[128/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.59515, val loss: 0.59901, in 0.019s\n",
      "[129/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.59500, val loss: 0.59892, in 0.020s\n",
      "[130/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59486, val loss: 0.59884, in 0.020s\n",
      "[131/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.59476, val loss: 0.59881, in 0.018s\n",
      "[132/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.59466, val loss: 0.59876, in 0.017s\n",
      "[133/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59446, val loss: 0.59859, in 0.021s\n",
      "[134/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59437, val loss: 0.59858, in 0.018s\n",
      "[135/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.59420, val loss: 0.59847, in 0.021s\n",
      "[136/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59410, val loss: 0.59839, in 0.019s\n",
      "[137/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59387, val loss: 0.59822, in 0.021s\n",
      "[138/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.59366, val loss: 0.59807, in 0.023s\n",
      "[139/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59358, val loss: 0.59805, in 0.018s\n",
      "[140/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.59335, val loss: 0.59787, in 0.024s\n",
      "[141/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59327, val loss: 0.59785, in 0.020s\n",
      "[142/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59313, val loss: 0.59777, in 0.020s\n",
      "[143/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59299, val loss: 0.59768, in 0.021s\n",
      "[144/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59284, val loss: 0.59756, in 0.020s\n",
      "[145/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.59266, val loss: 0.59744, in 0.021s\n",
      "[146/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59259, val loss: 0.59742, in 0.018s\n",
      "[147/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59242, val loss: 0.59730, in 0.020s\n",
      "[148/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59234, val loss: 0.59728, in 0.018s\n",
      "[149/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.59213, val loss: 0.59710, in 0.021s\n",
      "[150/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59194, val loss: 0.59693, in 0.020s\n",
      "[151/10000] 1 tree, 31 leaves, max depth = 17, train loss: 0.59177, val loss: 0.59681, in 0.026s\n",
      "[152/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59168, val loss: 0.59677, in 0.029s\n",
      "[153/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59145, val loss: 0.59657, in 0.030s\n",
      "[154/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.59127, val loss: 0.59641, in 0.017s\n",
      "[155/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59111, val loss: 0.59628, in 0.018s\n",
      "[156/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.59095, val loss: 0.59614, in 0.021s\n",
      "[157/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59083, val loss: 0.59606, in 0.023s\n",
      "[158/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59077, val loss: 0.59604, in 0.016s\n",
      "[159/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59063, val loss: 0.59595, in 0.019s\n",
      "[160/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.59045, val loss: 0.59581, in 0.022s\n",
      "[161/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.59030, val loss: 0.59572, in 0.023s\n",
      "[162/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.59020, val loss: 0.59566, in 0.021s\n",
      "[163/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.58997, val loss: 0.59544, in 0.023s\n",
      "[164/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58988, val loss: 0.59538, in 0.019s\n",
      "[165/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.58982, val loss: 0.59538, in 0.019s\n",
      "[166/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58965, val loss: 0.59527, in 0.022s\n",
      "[167/10000] 1 tree, 31 leaves, max depth = 7, train loss: 0.58950, val loss: 0.59516, in 0.023s\n",
      "[168/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58943, val loss: 0.59516, in 0.018s\n",
      "[169/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.58928, val loss: 0.59501, in 0.021s\n",
      "[170/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58922, val loss: 0.59499, in 0.019s\n",
      "[171/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58910, val loss: 0.59493, in 0.021s\n",
      "[172/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58899, val loss: 0.59489, in 0.020s\n",
      "[173/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58875, val loss: 0.59471, in 0.022s\n",
      "[174/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58861, val loss: 0.59458, in 0.024s\n",
      "[175/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58837, val loss: 0.59436, in 0.022s\n",
      "[176/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58818, val loss: 0.59421, in 0.021s\n",
      "[177/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58803, val loss: 0.59415, in 0.021s\n",
      "[178/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58789, val loss: 0.59404, in 0.025s\n",
      "[179/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58778, val loss: 0.59398, in 0.020s\n",
      "[180/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58766, val loss: 0.59394, in 0.021s\n",
      "[181/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58761, val loss: 0.59393, in 0.020s\n",
      "[182/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58744, val loss: 0.59383, in 0.023s\n",
      "[183/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58738, val loss: 0.59382, in 0.019s\n",
      "[184/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.58721, val loss: 0.59368, in 0.020s\n",
      "[185/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58710, val loss: 0.59359, in 0.020s\n",
      "[186/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58683, val loss: 0.59337, in 0.024s\n",
      "[187/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58671, val loss: 0.59330, in 0.024s\n",
      "[188/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.58658, val loss: 0.59322, in 0.023s\n",
      "[189/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58648, val loss: 0.59320, in 0.032s\n",
      "[190/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.58639, val loss: 0.59315, in 0.020s\n",
      "[191/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58634, val loss: 0.59314, in 0.019s\n",
      "[192/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58627, val loss: 0.59311, in 0.018s\n",
      "[193/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58621, val loss: 0.59310, in 0.017s\n",
      "[194/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58607, val loss: 0.59303, in 0.021s\n",
      "[195/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58592, val loss: 0.59291, in 0.021s\n",
      "[196/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58580, val loss: 0.59282, in 0.022s\n",
      "[197/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58574, val loss: 0.59282, in 0.020s\n",
      "[198/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58563, val loss: 0.59275, in 0.021s\n",
      "[199/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58556, val loss: 0.59274, in 0.020s\n",
      "[200/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.58539, val loss: 0.59261, in 0.021s\n",
      "[201/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.58528, val loss: 0.59255, in 0.033s\n",
      "[202/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58508, val loss: 0.59239, in 0.024s\n",
      "[203/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.58494, val loss: 0.59228, in 0.020s\n",
      "[204/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58479, val loss: 0.59213, in 0.021s\n",
      "[205/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58465, val loss: 0.59202, in 0.021s\n",
      "[206/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58453, val loss: 0.59194, in 0.018s\n",
      "[207/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58446, val loss: 0.59191, in 0.018s\n",
      "[208/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58435, val loss: 0.59188, in 0.018s\n",
      "[209/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58422, val loss: 0.59180, in 0.019s\n",
      "[210/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.58411, val loss: 0.59171, in 0.019s\n",
      "[211/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58391, val loss: 0.59153, in 0.019s\n",
      "[212/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.58384, val loss: 0.59154, in 0.018s\n",
      "[213/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.58380, val loss: 0.59153, in 0.016s\n",
      "[214/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.58367, val loss: 0.59143, in 0.020s\n",
      "[215/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.58345, val loss: 0.59131, in 0.019s\n",
      "[216/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58339, val loss: 0.59131, in 0.016s\n",
      "[217/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.58332, val loss: 0.59129, in 0.017s\n",
      "[218/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58315, val loss: 0.59115, in 0.021s\n",
      "[219/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58303, val loss: 0.59109, in 0.021s\n",
      "[220/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58286, val loss: 0.59095, in 0.020s\n",
      "[221/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58276, val loss: 0.59090, in 0.020s\n",
      "[222/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58266, val loss: 0.59084, in 0.018s\n",
      "[223/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58260, val loss: 0.59079, in 0.018s\n",
      "[224/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58249, val loss: 0.59072, in 0.022s\n",
      "[225/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58236, val loss: 0.59062, in 0.020s\n",
      "[226/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58230, val loss: 0.59061, in 0.019s\n",
      "[227/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58220, val loss: 0.59054, in 0.021s\n",
      "[228/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58211, val loss: 0.59052, in 0.020s\n",
      "[229/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58192, val loss: 0.59038, in 0.025s\n",
      "[230/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.58182, val loss: 0.59032, in 0.019s\n",
      "[231/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58176, val loss: 0.59027, in 0.017s\n",
      "[232/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58162, val loss: 0.59016, in 0.019s\n",
      "[233/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.58142, val loss: 0.58999, in 0.021s\n",
      "[234/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58135, val loss: 0.58997, in 0.019s\n",
      "[235/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58124, val loss: 0.58991, in 0.018s\n",
      "[236/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58112, val loss: 0.58988, in 0.018s\n",
      "[237/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58094, val loss: 0.58978, in 0.019s\n",
      "[238/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58084, val loss: 0.58972, in 0.021s\n",
      "[239/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58075, val loss: 0.58968, in 0.019s\n",
      "[240/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58063, val loss: 0.58959, in 0.023s\n",
      "[241/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.58056, val loss: 0.58959, in 0.018s\n",
      "[242/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.58052, val loss: 0.58958, in 0.016s\n",
      "[243/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58047, val loss: 0.58958, in 0.018s\n",
      "[244/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58036, val loss: 0.58953, in 0.019s\n",
      "[245/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58022, val loss: 0.58944, in 0.020s\n",
      "[246/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.58013, val loss: 0.58937, in 0.019s\n",
      "[247/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58005, val loss: 0.58933, in 0.021s\n",
      "[248/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58000, val loss: 0.58932, in 0.016s\n",
      "[249/10000] 1 tree, 31 leaves, max depth = 18, train loss: 0.57996, val loss: 0.58933, in 0.017s\n",
      "[250/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57989, val loss: 0.58932, in 0.017s\n",
      "[251/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.57972, val loss: 0.58919, in 0.021s\n",
      "[252/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57958, val loss: 0.58908, in 0.030s\n",
      "[253/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57948, val loss: 0.58903, in 0.020s\n",
      "[254/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57935, val loss: 0.58893, in 0.021s\n",
      "[255/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57929, val loss: 0.58890, in 0.020s\n",
      "[256/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57922, val loss: 0.58886, in 0.021s\n",
      "[257/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57912, val loss: 0.58879, in 0.023s\n",
      "[258/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.57903, val loss: 0.58874, in 0.022s\n",
      "[259/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57898, val loss: 0.58873, in 0.018s\n",
      "[260/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57887, val loss: 0.58865, in 0.020s\n",
      "[261/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57881, val loss: 0.58864, in 0.019s\n",
      "[262/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.57866, val loss: 0.58851, in 0.020s\n",
      "[263/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.57854, val loss: 0.58840, in 0.032s\n",
      "[264/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57843, val loss: 0.58834, in 0.020s\n",
      "[265/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57827, val loss: 0.58821, in 0.021s\n",
      "[266/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57815, val loss: 0.58812, in 0.022s\n",
      "[267/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57809, val loss: 0.58809, in 0.018s\n",
      "[268/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57804, val loss: 0.58806, in 0.018s\n",
      "[269/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.57799, val loss: 0.58806, in 0.019s\n",
      "[270/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57791, val loss: 0.58800, in 0.020s\n",
      "[271/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57782, val loss: 0.58795, in 0.022s\n",
      "[272/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57775, val loss: 0.58795, in 0.019s\n",
      "[273/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57761, val loss: 0.58783, in 0.024s\n",
      "[274/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57749, val loss: 0.58774, in 0.021s\n",
      "[275/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57743, val loss: 0.58774, in 0.019s\n",
      "[276/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57728, val loss: 0.58762, in 0.025s\n",
      "[277/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.57724, val loss: 0.58761, in 0.018s\n",
      "[278/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57715, val loss: 0.58756, in 0.019s\n",
      "[279/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57704, val loss: 0.58749, in 0.022s\n",
      "[280/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57698, val loss: 0.58749, in 0.020s\n",
      "[281/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.57688, val loss: 0.58740, in 0.022s\n",
      "[282/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.57684, val loss: 0.58741, in 0.019s\n",
      "[283/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57677, val loss: 0.58740, in 0.021s\n",
      "[284/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57670, val loss: 0.58737, in 0.023s\n",
      "[285/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57664, val loss: 0.58738, in 0.019s\n",
      "[286/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57653, val loss: 0.58732, in 0.022s\n",
      "[287/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57642, val loss: 0.58724, in 0.022s\n",
      "[288/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.57630, val loss: 0.58715, in 0.021s\n",
      "[289/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57615, val loss: 0.58704, in 0.020s\n",
      "[290/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57606, val loss: 0.58701, in 0.019s\n",
      "[291/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.57591, val loss: 0.58687, in 0.021s\n",
      "[292/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57586, val loss: 0.58685, in 0.019s\n",
      "[293/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57571, val loss: 0.58674, in 0.023s\n",
      "[294/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57562, val loss: 0.58669, in 0.021s\n",
      "[295/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57554, val loss: 0.58667, in 0.018s\n",
      "[296/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57543, val loss: 0.58657, in 0.021s\n",
      "[297/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57534, val loss: 0.58653, in 0.021s\n",
      "[298/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57522, val loss: 0.58643, in 0.021s\n",
      "[299/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57506, val loss: 0.58634, in 0.020s\n",
      "[300/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57494, val loss: 0.58625, in 0.024s\n",
      "[301/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.57487, val loss: 0.58622, in 0.025s\n",
      "[302/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57475, val loss: 0.58614, in 0.021s\n",
      "[303/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57466, val loss: 0.58612, in 0.040s\n",
      "[304/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.57460, val loss: 0.58612, in 0.029s\n",
      "[305/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57452, val loss: 0.58608, in 0.023s\n",
      "[306/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.57443, val loss: 0.58605, in 0.023s\n",
      "[307/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57435, val loss: 0.58600, in 0.021s\n",
      "[308/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57429, val loss: 0.58599, in 0.019s\n",
      "[309/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57425, val loss: 0.58599, in 0.015s\n",
      "[310/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57415, val loss: 0.58596, in 0.017s\n",
      "[311/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.57407, val loss: 0.58592, in 0.020s\n",
      "[312/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57392, val loss: 0.58582, in 0.022s\n",
      "[313/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57375, val loss: 0.58570, in 0.020s\n",
      "[314/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57360, val loss: 0.58559, in 0.020s\n",
      "[315/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57350, val loss: 0.58554, in 0.020s\n",
      "[316/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57343, val loss: 0.58553, in 0.018s\n",
      "[317/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57334, val loss: 0.58549, in 0.021s\n",
      "[318/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57327, val loss: 0.58544, in 0.017s\n",
      "[319/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57318, val loss: 0.58542, in 0.019s\n",
      "[320/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57308, val loss: 0.58535, in 0.019s\n",
      "[321/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57298, val loss: 0.58532, in 0.021s\n",
      "[322/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57283, val loss: 0.58520, in 0.021s\n",
      "[323/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57272, val loss: 0.58516, in 0.029s\n",
      "[324/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57262, val loss: 0.58512, in 0.019s\n",
      "[325/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57255, val loss: 0.58509, in 0.017s\n",
      "[326/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57251, val loss: 0.58509, in 0.017s\n",
      "[327/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57242, val loss: 0.58503, in 0.020s\n",
      "[328/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57232, val loss: 0.58497, in 0.019s\n",
      "[329/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57228, val loss: 0.58496, in 0.017s\n",
      "[330/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57216, val loss: 0.58492, in 0.021s\n",
      "[331/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57207, val loss: 0.58488, in 0.020s\n",
      "[332/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57201, val loss: 0.58486, in 0.019s\n",
      "[333/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57192, val loss: 0.58483, in 0.019s\n",
      "[334/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57181, val loss: 0.58475, in 0.104s\n",
      "[335/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57174, val loss: 0.58474, in 0.017s\n",
      "[336/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57166, val loss: 0.58471, in 0.019s\n",
      "[337/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57154, val loss: 0.58460, in 0.021s\n",
      "[338/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.57145, val loss: 0.58457, in 0.018s\n",
      "[339/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57135, val loss: 0.58450, in 0.021s\n",
      "[340/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57130, val loss: 0.58449, in 0.016s\n",
      "[341/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57125, val loss: 0.58450, in 0.017s\n",
      "[342/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57119, val loss: 0.58448, in 0.016s\n",
      "[343/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57114, val loss: 0.58448, in 0.018s\n",
      "[344/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57107, val loss: 0.58446, in 0.018s\n",
      "[345/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57103, val loss: 0.58446, in 0.016s\n",
      "[346/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57093, val loss: 0.58441, in 0.030s\n",
      "[347/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57084, val loss: 0.58433, in 0.020s\n",
      "[348/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.57075, val loss: 0.58432, in 0.021s\n",
      "[349/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57064, val loss: 0.58424, in 0.019s\n",
      "[350/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57056, val loss: 0.58421, in 0.021s\n",
      "[351/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.57050, val loss: 0.58418, in 0.020s\n",
      "[352/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.57042, val loss: 0.58413, in 0.018s\n",
      "[353/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57032, val loss: 0.58407, in 0.021s\n",
      "[354/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.57028, val loss: 0.58406, in 0.018s\n",
      "[355/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57018, val loss: 0.58402, in 0.022s\n",
      "[356/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57007, val loss: 0.58395, in 0.020s\n",
      "[357/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56995, val loss: 0.58389, in 0.021s\n",
      "[358/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56991, val loss: 0.58390, in 0.020s\n",
      "[359/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56982, val loss: 0.58384, in 0.020s\n",
      "[360/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56974, val loss: 0.58381, in 0.019s\n",
      "[361/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56965, val loss: 0.58382, in 0.024s\n",
      "[362/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.56955, val loss: 0.58376, in 0.021s\n",
      "[363/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56944, val loss: 0.58370, in 0.020s\n",
      "[364/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56932, val loss: 0.58361, in 0.019s\n",
      "[365/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56914, val loss: 0.58346, in 0.021s\n",
      "[366/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56908, val loss: 0.58347, in 0.020s\n",
      "[367/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.56897, val loss: 0.58343, in 0.021s\n",
      "[368/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56885, val loss: 0.58336, in 0.020s\n",
      "[369/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.56877, val loss: 0.58333, in 0.023s\n",
      "[370/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56870, val loss: 0.58330, in 0.020s\n",
      "[371/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56863, val loss: 0.58328, in 0.032s\n",
      "[372/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56859, val loss: 0.58329, in 0.016s\n",
      "[373/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56856, val loss: 0.58329, in 0.017s\n",
      "[374/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56849, val loss: 0.58328, in 0.020s\n",
      "[375/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56842, val loss: 0.58327, in 0.022s\n",
      "[376/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56831, val loss: 0.58318, in 0.021s\n",
      "[377/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56822, val loss: 0.58312, in 0.021s\n",
      "[378/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56815, val loss: 0.58312, in 0.022s\n",
      "[379/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56808, val loss: 0.58310, in 0.021s\n",
      "[380/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56795, val loss: 0.58301, in 0.021s\n",
      "[381/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56788, val loss: 0.58300, in 0.020s\n",
      "[382/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56781, val loss: 0.58298, in 0.021s\n",
      "[383/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56776, val loss: 0.58298, in 0.021s\n",
      "[384/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56770, val loss: 0.58295, in 0.021s\n",
      "[385/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56765, val loss: 0.58296, in 0.020s\n",
      "[386/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56752, val loss: 0.58291, in 0.029s\n",
      "[387/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56744, val loss: 0.58285, in 0.023s\n",
      "[388/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56737, val loss: 0.58282, in 0.022s\n",
      "[389/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56733, val loss: 0.58282, in 0.021s\n",
      "[390/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.56727, val loss: 0.58282, in 0.020s\n",
      "[391/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56717, val loss: 0.58275, in 0.024s\n",
      "[392/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56706, val loss: 0.58271, in 0.025s\n",
      "[393/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56698, val loss: 0.58265, in 0.022s\n",
      "[394/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56689, val loss: 0.58261, in 0.032s\n",
      "[395/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.56683, val loss: 0.58258, in 0.020s\n",
      "[396/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56676, val loss: 0.58255, in 0.021s\n",
      "[397/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.56668, val loss: 0.58249, in 0.021s\n",
      "[398/10000] 1 tree, 31 leaves, max depth = 17, train loss: 0.56665, val loss: 0.58251, in 0.018s\n",
      "[399/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.56656, val loss: 0.58245, in 0.020s\n",
      "[400/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.56649, val loss: 0.58243, in 0.021s\n",
      "[401/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56641, val loss: 0.58239, in 0.019s\n",
      "[402/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56634, val loss: 0.58235, in 0.021s\n",
      "[403/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56625, val loss: 0.58233, in 0.021s\n",
      "[404/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56615, val loss: 0.58226, in 0.021s\n",
      "[405/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56606, val loss: 0.58225, in 0.021s\n",
      "[406/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56597, val loss: 0.58222, in 0.020s\n",
      "[407/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56590, val loss: 0.58220, in 0.022s\n",
      "[408/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.56583, val loss: 0.58217, in 0.020s\n",
      "[409/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.56575, val loss: 0.58214, in 0.020s\n",
      "[410/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56565, val loss: 0.58208, in 0.021s\n",
      "[411/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56561, val loss: 0.58209, in 0.018s\n",
      "[412/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56552, val loss: 0.58206, in 0.020s\n",
      "[413/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56548, val loss: 0.58206, in 0.024s\n",
      "[414/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56540, val loss: 0.58203, in 0.019s\n",
      "[415/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56533, val loss: 0.58198, in 0.019s\n",
      "[416/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56527, val loss: 0.58198, in 0.021s\n",
      "[417/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56519, val loss: 0.58194, in 0.020s\n",
      "[418/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56513, val loss: 0.58194, in 0.020s\n",
      "[419/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56505, val loss: 0.58191, in 0.019s\n",
      "[420/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56501, val loss: 0.58189, in 0.017s\n",
      "[421/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56494, val loss: 0.58185, in 0.019s\n",
      "[422/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56487, val loss: 0.58182, in 0.019s\n",
      "[423/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56480, val loss: 0.58181, in 0.018s\n",
      "[424/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56475, val loss: 0.58181, in 0.018s\n",
      "[425/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56470, val loss: 0.58180, in 0.017s\n",
      "[426/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56462, val loss: 0.58176, in 0.018s\n",
      "[427/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56451, val loss: 0.58173, in 0.021s\n",
      "[428/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56443, val loss: 0.58169, in 0.023s\n",
      "[429/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56430, val loss: 0.58163, in 0.022s\n",
      "[430/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56422, val loss: 0.58161, in 0.020s\n",
      "[431/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56411, val loss: 0.58155, in 0.022s\n",
      "[432/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56403, val loss: 0.58151, in 0.032s\n",
      "[433/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56394, val loss: 0.58145, in 0.023s\n",
      "[434/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56387, val loss: 0.58143, in 0.019s\n",
      "[435/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56380, val loss: 0.58143, in 0.018s\n",
      "[436/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56371, val loss: 0.58139, in 0.021s\n",
      "[437/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56365, val loss: 0.58139, in 0.020s\n",
      "[438/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56358, val loss: 0.58137, in 0.018s\n",
      "[439/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.56349, val loss: 0.58135, in 0.019s\n",
      "[440/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.56344, val loss: 0.58134, in 0.016s\n",
      "[441/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56336, val loss: 0.58134, in 0.018s\n",
      "[442/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56333, val loss: 0.58133, in 0.015s\n",
      "[443/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56329, val loss: 0.58133, in 0.017s\n",
      "[444/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56318, val loss: 0.58125, in 0.032s\n",
      "[445/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56311, val loss: 0.58123, in 0.020s\n",
      "[446/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56303, val loss: 0.58120, in 0.020s\n",
      "[447/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.56300, val loss: 0.58120, in 0.018s\n",
      "[448/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.56294, val loss: 0.58115, in 0.020s\n",
      "[449/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56286, val loss: 0.58110, in 0.020s\n",
      "[450/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56280, val loss: 0.58109, in 0.019s\n",
      "[451/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56272, val loss: 0.58106, in 0.020s\n",
      "[452/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.56259, val loss: 0.58097, in 0.019s\n",
      "[453/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56245, val loss: 0.58083, in 0.022s\n",
      "[454/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56237, val loss: 0.58082, in 0.020s\n",
      "[455/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56223, val loss: 0.58070, in 0.018s\n",
      "[456/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56217, val loss: 0.58069, in 0.018s\n",
      "[457/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56208, val loss: 0.58067, in 0.031s\n",
      "[458/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56202, val loss: 0.58068, in 0.021s\n",
      "[459/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56192, val loss: 0.58066, in 0.023s\n",
      "[460/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56187, val loss: 0.58067, in 0.017s\n",
      "[461/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56181, val loss: 0.58063, in 0.019s\n",
      "[462/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56174, val loss: 0.58061, in 0.022s\n",
      "[463/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56164, val loss: 0.58055, in 0.019s\n",
      "[464/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56160, val loss: 0.58054, in 0.016s\n",
      "[465/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.56154, val loss: 0.58054, in 0.019s\n",
      "[466/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56146, val loss: 0.58052, in 0.020s\n",
      "[467/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56137, val loss: 0.58047, in 0.021s\n",
      "[468/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56131, val loss: 0.58047, in 0.020s\n",
      "[469/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.56126, val loss: 0.58047, in 0.020s\n",
      "[470/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56122, val loss: 0.58047, in 0.018s\n",
      "[471/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56114, val loss: 0.58043, in 0.022s\n",
      "[472/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56111, val loss: 0.58043, in 0.017s\n",
      "[473/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56107, val loss: 0.58044, in 0.018s\n",
      "[474/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56100, val loss: 0.58041, in 0.019s\n",
      "[475/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56097, val loss: 0.58041, in 0.016s\n",
      "[476/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56090, val loss: 0.58039, in 0.020s\n",
      "[477/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56083, val loss: 0.58036, in 0.020s\n",
      "[478/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56076, val loss: 0.58032, in 0.021s\n",
      "[479/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56067, val loss: 0.58027, in 0.018s\n",
      "[480/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56061, val loss: 0.58026, in 0.018s\n",
      "[481/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56055, val loss: 0.58025, in 0.021s\n",
      "[482/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56051, val loss: 0.58025, in 0.019s\n",
      "[483/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56047, val loss: 0.58024, in 0.018s\n",
      "[484/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56041, val loss: 0.58024, in 0.019s\n",
      "[485/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.56035, val loss: 0.58022, in 0.022s\n",
      "[486/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56029, val loss: 0.58021, in 0.020s\n",
      "[487/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56023, val loss: 0.58020, in 0.020s\n",
      "[488/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56018, val loss: 0.58020, in 0.019s\n",
      "[489/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.56011, val loss: 0.58018, in 0.022s\n",
      "[490/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56006, val loss: 0.58019, in 0.018s\n",
      "[491/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56001, val loss: 0.58017, in 0.019s\n",
      "[492/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55995, val loss: 0.58012, in 0.026s\n",
      "[493/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55990, val loss: 0.58011, in 0.019s\n",
      "[494/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55984, val loss: 0.58009, in 0.037s\n",
      "[495/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55975, val loss: 0.58004, in 0.019s\n",
      "[496/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55968, val loss: 0.58001, in 0.019s\n",
      "[497/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55962, val loss: 0.57999, in 0.017s\n",
      "[498/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55955, val loss: 0.57998, in 0.018s\n",
      "[499/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55949, val loss: 0.57997, in 0.018s\n",
      "[500/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55944, val loss: 0.57997, in 0.018s\n",
      "[501/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55938, val loss: 0.57995, in 0.018s\n",
      "[502/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55931, val loss: 0.57994, in 0.019s\n",
      "[503/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55925, val loss: 0.57993, in 0.018s\n",
      "[504/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55922, val loss: 0.57992, in 0.017s\n",
      "[505/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55918, val loss: 0.57992, in 0.019s\n",
      "[506/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55911, val loss: 0.57991, in 0.018s\n",
      "[507/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55904, val loss: 0.57989, in 0.018s\n",
      "[508/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55895, val loss: 0.57984, in 0.018s\n",
      "[509/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55886, val loss: 0.57979, in 0.019s\n",
      "[510/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.55877, val loss: 0.57976, in 0.017s\n",
      "[511/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55873, val loss: 0.57976, in 0.018s\n",
      "[512/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55866, val loss: 0.57974, in 0.017s\n",
      "[513/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55863, val loss: 0.57974, in 0.015s\n",
      "[514/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55857, val loss: 0.57971, in 0.016s\n",
      "[515/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55853, val loss: 0.57969, in 0.016s\n",
      "[516/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55848, val loss: 0.57969, in 0.018s\n",
      "[517/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55839, val loss: 0.57968, in 0.017s\n",
      "[518/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55834, val loss: 0.57968, in 0.018s\n",
      "[519/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55828, val loss: 0.57968, in 0.018s\n",
      "[520/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55823, val loss: 0.57968, in 0.017s\n",
      "[521/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55818, val loss: 0.57968, in 0.016s\n",
      "[522/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55810, val loss: 0.57964, in 0.021s\n",
      "[523/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55806, val loss: 0.57964, in 0.018s\n",
      "[524/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55800, val loss: 0.57961, in 0.020s\n",
      "[525/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55792, val loss: 0.57956, in 0.021s\n",
      "[526/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55786, val loss: 0.57956, in 0.018s\n",
      "[527/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55780, val loss: 0.57955, in 0.028s\n",
      "[528/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.55770, val loss: 0.57951, in 0.023s\n",
      "[529/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55763, val loss: 0.57948, in 0.020s\n",
      "[530/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55760, val loss: 0.57949, in 0.016s\n",
      "[531/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55753, val loss: 0.57947, in 0.020s\n",
      "[532/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55747, val loss: 0.57947, in 0.018s\n",
      "[533/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55742, val loss: 0.57947, in 0.018s\n",
      "[534/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55736, val loss: 0.57945, in 0.017s\n",
      "[535/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55733, val loss: 0.57947, in 0.016s\n",
      "[536/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55728, val loss: 0.57946, in 0.016s\n",
      "[537/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55722, val loss: 0.57944, in 0.018s\n",
      "[538/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55712, val loss: 0.57937, in 0.017s\n",
      "[539/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55708, val loss: 0.57935, in 0.017s\n",
      "[540/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55704, val loss: 0.57935, in 0.017s\n",
      "[541/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55699, val loss: 0.57934, in 0.016s\n",
      "[542/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55693, val loss: 0.57931, in 0.017s\n",
      "[543/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55689, val loss: 0.57933, in 0.017s\n",
      "[544/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55680, val loss: 0.57926, in 0.017s\n",
      "[545/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55675, val loss: 0.57925, in 0.017s\n",
      "[546/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55671, val loss: 0.57924, in 0.017s\n",
      "[547/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55660, val loss: 0.57921, in 0.019s\n",
      "[548/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55650, val loss: 0.57914, in 0.025s\n",
      "[549/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55642, val loss: 0.57911, in 0.018s\n",
      "[550/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55634, val loss: 0.57908, in 0.019s\n",
      "[551/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55626, val loss: 0.57906, in 0.020s\n",
      "[552/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55620, val loss: 0.57905, in 0.026s\n",
      "[553/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55615, val loss: 0.57903, in 0.025s\n",
      "[554/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55609, val loss: 0.57899, in 0.021s\n",
      "[555/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55604, val loss: 0.57897, in 0.019s\n",
      "[556/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55596, val loss: 0.57895, in 0.017s\n",
      "[557/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55591, val loss: 0.57894, in 0.019s\n",
      "[558/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55584, val loss: 0.57892, in 0.020s\n",
      "[559/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55576, val loss: 0.57887, in 0.029s\n",
      "[560/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55569, val loss: 0.57882, in 0.018s\n",
      "[561/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55561, val loss: 0.57880, in 0.020s\n",
      "[562/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55556, val loss: 0.57878, in 0.019s\n",
      "[563/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55550, val loss: 0.57877, in 0.020s\n",
      "[564/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55544, val loss: 0.57876, in 0.018s\n",
      "[565/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55539, val loss: 0.57874, in 0.019s\n",
      "[566/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55532, val loss: 0.57872, in 0.020s\n",
      "[567/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55524, val loss: 0.57867, in 0.019s\n",
      "[568/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55518, val loss: 0.57866, in 0.019s\n",
      "[569/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55507, val loss: 0.57854, in 0.020s\n",
      "[570/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55500, val loss: 0.57848, in 0.019s\n",
      "[571/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55494, val loss: 0.57846, in 0.019s\n",
      "[572/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55486, val loss: 0.57843, in 0.020s\n",
      "[573/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55480, val loss: 0.57842, in 0.020s\n",
      "[574/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.55477, val loss: 0.57842, in 0.016s\n",
      "[575/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55471, val loss: 0.57840, in 0.017s\n",
      "[576/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55468, val loss: 0.57839, in 0.017s\n",
      "[577/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55461, val loss: 0.57838, in 0.021s\n",
      "[578/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55456, val loss: 0.57840, in 0.017s\n",
      "[579/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55450, val loss: 0.57839, in 0.017s\n",
      "[580/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55444, val loss: 0.57837, in 0.020s\n",
      "[581/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55436, val loss: 0.57832, in 0.022s\n",
      "[582/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55428, val loss: 0.57829, in 0.018s\n",
      "[583/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55423, val loss: 0.57827, in 0.019s\n",
      "[584/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55416, val loss: 0.57825, in 0.020s\n",
      "[585/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55408, val loss: 0.57822, in 0.023s\n",
      "[586/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55404, val loss: 0.57823, in 0.020s\n",
      "[587/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55393, val loss: 0.57816, in 0.022s\n",
      "[588/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55383, val loss: 0.57810, in 0.019s\n",
      "[589/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55374, val loss: 0.57807, in 0.021s\n",
      "[590/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55367, val loss: 0.57806, in 0.020s\n",
      "[591/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55357, val loss: 0.57795, in 0.022s\n",
      "[592/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55352, val loss: 0.57796, in 0.019s\n",
      "[593/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55347, val loss: 0.57795, in 0.020s\n",
      "[594/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55342, val loss: 0.57794, in 0.018s\n",
      "[595/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55335, val loss: 0.57791, in 0.019s\n",
      "[596/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55327, val loss: 0.57785, in 0.017s\n",
      "[597/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55318, val loss: 0.57778, in 0.021s\n",
      "[598/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55312, val loss: 0.57776, in 0.020s\n",
      "[599/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55306, val loss: 0.57776, in 0.032s\n",
      "[600/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55300, val loss: 0.57774, in 0.019s\n",
      "[601/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55295, val loss: 0.57772, in 0.017s\n",
      "[602/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55289, val loss: 0.57769, in 0.018s\n",
      "[603/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55284, val loss: 0.57769, in 0.016s\n",
      "[604/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55278, val loss: 0.57767, in 0.019s\n",
      "[605/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55272, val loss: 0.57766, in 0.017s\n",
      "[606/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55264, val loss: 0.57762, in 0.017s\n",
      "[607/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55257, val loss: 0.57760, in 0.017s\n",
      "[608/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55247, val loss: 0.57754, in 0.019s\n",
      "[609/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55241, val loss: 0.57752, in 0.018s\n",
      "[610/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55235, val loss: 0.57751, in 0.019s\n",
      "[611/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55231, val loss: 0.57752, in 0.019s\n",
      "[612/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55223, val loss: 0.57749, in 0.020s\n",
      "[613/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55215, val loss: 0.57745, in 0.020s\n",
      "[614/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55206, val loss: 0.57742, in 0.019s\n",
      "[615/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55199, val loss: 0.57740, in 0.020s\n",
      "[616/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55194, val loss: 0.57740, in 0.019s\n",
      "[617/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55190, val loss: 0.57739, in 0.017s\n",
      "[618/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55184, val loss: 0.57739, in 0.020s\n",
      "[619/10000] 1 tree, 31 leaves, max depth = 17, train loss: 0.55176, val loss: 0.57736, in 0.020s\n",
      "[620/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55173, val loss: 0.57737, in 0.017s\n",
      "[621/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55166, val loss: 0.57734, in 0.017s\n",
      "[622/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55160, val loss: 0.57735, in 0.017s\n",
      "[623/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55153, val loss: 0.57735, in 0.017s\n",
      "[624/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55143, val loss: 0.57728, in 0.018s\n",
      "[625/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55133, val loss: 0.57722, in 0.021s\n",
      "[626/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55129, val loss: 0.57720, in 0.014s\n",
      "[627/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55124, val loss: 0.57720, in 0.018s\n",
      "[628/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55114, val loss: 0.57711, in 0.020s\n",
      "[629/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55107, val loss: 0.57710, in 0.020s\n",
      "[630/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55094, val loss: 0.57699, in 0.036s\n",
      "[631/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55088, val loss: 0.57696, in 0.022s\n",
      "[632/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55081, val loss: 0.57693, in 0.019s\n",
      "[633/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55077, val loss: 0.57693, in 0.017s\n",
      "[634/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55069, val loss: 0.57689, in 0.019s\n",
      "[635/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55064, val loss: 0.57688, in 0.019s\n",
      "[636/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.55060, val loss: 0.57686, in 0.017s\n",
      "[637/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55053, val loss: 0.57685, in 0.019s\n",
      "[638/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55047, val loss: 0.57683, in 0.018s\n",
      "[639/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55040, val loss: 0.57680, in 0.017s\n",
      "[640/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55034, val loss: 0.57677, in 0.018s\n",
      "[641/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55031, val loss: 0.57676, in 0.016s\n",
      "[642/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55027, val loss: 0.57677, in 0.017s\n",
      "[643/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55021, val loss: 0.57674, in 0.021s\n",
      "[644/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55011, val loss: 0.57670, in 0.020s\n",
      "[645/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55004, val loss: 0.57669, in 0.019s\n",
      "[646/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54999, val loss: 0.57669, in 0.018s\n",
      "[647/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54991, val loss: 0.57667, in 0.019s\n",
      "[648/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54985, val loss: 0.57664, in 0.019s\n",
      "[649/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54982, val loss: 0.57664, in 0.015s\n",
      "[650/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54976, val loss: 0.57661, in 0.017s\n",
      "[651/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54969, val loss: 0.57657, in 0.018s\n",
      "[652/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54966, val loss: 0.57659, in 0.024s\n",
      "[653/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54963, val loss: 0.57658, in 0.017s\n",
      "[654/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54958, val loss: 0.57657, in 0.019s\n",
      "[655/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54952, val loss: 0.57656, in 0.021s\n",
      "[656/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54947, val loss: 0.57655, in 0.018s\n",
      "[657/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54941, val loss: 0.57655, in 0.018s\n",
      "[658/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54936, val loss: 0.57655, in 0.020s\n",
      "[659/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54931, val loss: 0.57653, in 0.019s\n",
      "[660/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54925, val loss: 0.57651, in 0.020s\n",
      "[661/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54918, val loss: 0.57650, in 0.023s\n",
      "[662/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54912, val loss: 0.57650, in 0.020s\n",
      "[663/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54907, val loss: 0.57648, in 0.021s\n",
      "[664/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54903, val loss: 0.57649, in 0.019s\n",
      "[665/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54898, val loss: 0.57648, in 0.019s\n",
      "[666/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54894, val loss: 0.57648, in 0.017s\n",
      "[667/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54890, val loss: 0.57649, in 0.017s\n",
      "[668/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54885, val loss: 0.57649, in 0.018s\n",
      "[669/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54879, val loss: 0.57647, in 0.019s\n",
      "[670/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.54866, val loss: 0.57640, in 0.019s\n",
      "[671/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54859, val loss: 0.57639, in 0.021s\n",
      "[672/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54846, val loss: 0.57631, in 0.021s\n",
      "[673/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54840, val loss: 0.57631, in 0.019s\n",
      "[674/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54836, val loss: 0.57632, in 0.019s\n",
      "[675/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54833, val loss: 0.57633, in 0.017s\n",
      "[676/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54827, val loss: 0.57633, in 0.019s\n",
      "[677/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.54824, val loss: 0.57632, in 0.017s\n",
      "[678/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54820, val loss: 0.57631, in 0.018s\n",
      "[679/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54814, val loss: 0.57628, in 0.020s\n",
      "[680/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54811, val loss: 0.57629, in 0.019s\n",
      "[681/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54807, val loss: 0.57629, in 0.019s\n",
      "[682/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54801, val loss: 0.57627, in 0.019s\n",
      "[683/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54795, val loss: 0.57626, in 0.020s\n",
      "[684/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54788, val loss: 0.57624, in 0.019s\n",
      "[685/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54780, val loss: 0.57623, in 0.022s\n",
      "[686/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54772, val loss: 0.57622, in 0.019s\n",
      "[687/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54769, val loss: 0.57622, in 0.018s\n",
      "[688/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54763, val loss: 0.57622, in 0.018s\n",
      "[689/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54755, val loss: 0.57618, in 0.020s\n",
      "[690/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54749, val loss: 0.57616, in 0.018s\n",
      "[691/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54746, val loss: 0.57616, in 0.018s\n",
      "[692/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54741, val loss: 0.57615, in 0.019s\n",
      "[693/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54733, val loss: 0.57607, in 0.019s\n",
      "[694/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54725, val loss: 0.57604, in 0.022s\n",
      "[695/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54718, val loss: 0.57605, in 0.021s\n",
      "[696/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54714, val loss: 0.57604, in 0.019s\n",
      "[697/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54708, val loss: 0.57605, in 0.019s\n",
      "[698/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54703, val loss: 0.57604, in 0.019s\n",
      "[699/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54698, val loss: 0.57603, in 0.019s\n",
      "[700/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54691, val loss: 0.57601, in 0.021s\n",
      "[701/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54686, val loss: 0.57601, in 0.018s\n",
      "[702/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54681, val loss: 0.57601, in 0.022s\n",
      "[703/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54675, val loss: 0.57602, in 0.016s\n",
      "[704/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54668, val loss: 0.57599, in 0.036s\n",
      "[705/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54663, val loss: 0.57598, in 0.018s\n",
      "[706/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54655, val loss: 0.57594, in 0.017s\n",
      "[707/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54649, val loss: 0.57594, in 0.018s\n",
      "[708/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54646, val loss: 0.57594, in 0.017s\n",
      "[709/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54640, val loss: 0.57595, in 0.018s\n",
      "[710/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54633, val loss: 0.57593, in 0.018s\n",
      "[711/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54627, val loss: 0.57592, in 0.018s\n",
      "[712/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54620, val loss: 0.57589, in 0.020s\n",
      "[713/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54609, val loss: 0.57583, in 0.019s\n",
      "[714/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54600, val loss: 0.57575, in 0.018s\n",
      "[715/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54594, val loss: 0.57574, in 0.031s\n",
      "[716/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54589, val loss: 0.57573, in 0.028s\n",
      "[717/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54583, val loss: 0.57569, in 0.020s\n",
      "[718/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54576, val loss: 0.57569, in 0.019s\n",
      "[719/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54571, val loss: 0.57569, in 0.025s\n",
      "[720/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54563, val loss: 0.57565, in 0.022s\n",
      "[721/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54556, val loss: 0.57562, in 0.017s\n",
      "[722/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.54552, val loss: 0.57561, in 0.019s\n",
      "[723/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54546, val loss: 0.57557, in 0.017s\n",
      "[724/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54540, val loss: 0.57557, in 0.017s\n",
      "[725/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54535, val loss: 0.57557, in 0.016s\n",
      "[726/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54528, val loss: 0.57556, in 0.019s\n",
      "[727/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54523, val loss: 0.57554, in 0.018s\n",
      "[728/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54519, val loss: 0.57554, in 0.016s\n",
      "[729/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54515, val loss: 0.57555, in 0.017s\n",
      "[730/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54511, val loss: 0.57555, in 0.016s\n",
      "[731/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54505, val loss: 0.57551, in 0.019s\n",
      "[732/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54497, val loss: 0.57547, in 0.018s\n",
      "[733/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54491, val loss: 0.57544, in 0.019s\n",
      "[734/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54487, val loss: 0.57545, in 0.017s\n",
      "[735/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54485, val loss: 0.57546, in 0.015s\n",
      "[736/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54479, val loss: 0.57545, in 0.018s\n",
      "[737/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54473, val loss: 0.57543, in 0.019s\n",
      "[738/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54470, val loss: 0.57542, in 0.017s\n",
      "[739/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54462, val loss: 0.57538, in 0.023s\n",
      "[740/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54458, val loss: 0.57537, in 0.018s\n",
      "[741/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54448, val loss: 0.57532, in 0.022s\n",
      "[742/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54440, val loss: 0.57531, in 0.020s\n",
      "[743/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54435, val loss: 0.57530, in 0.020s\n",
      "[744/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54430, val loss: 0.57531, in 0.018s\n",
      "[745/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54421, val loss: 0.57528, in 0.018s\n",
      "[746/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54416, val loss: 0.57527, in 0.017s\n",
      "[747/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54412, val loss: 0.57527, in 0.017s\n",
      "[748/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54407, val loss: 0.57527, in 0.018s\n",
      "[749/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54401, val loss: 0.57526, in 0.017s\n",
      "[750/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54395, val loss: 0.57525, in 0.017s\n",
      "[751/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54391, val loss: 0.57526, in 0.016s\n",
      "[752/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54385, val loss: 0.57525, in 0.018s\n",
      "[753/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54383, val loss: 0.57525, in 0.016s\n",
      "[754/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54377, val loss: 0.57522, in 0.017s\n",
      "[755/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54375, val loss: 0.57523, in 0.017s\n",
      "[756/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54370, val loss: 0.57522, in 0.018s\n",
      "[757/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54364, val loss: 0.57521, in 0.020s\n",
      "[758/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54360, val loss: 0.57521, in 0.021s\n",
      "[759/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.54357, val loss: 0.57521, in 0.016s\n",
      "[760/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54353, val loss: 0.57522, in 0.018s\n",
      "[761/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54347, val loss: 0.57518, in 0.021s\n",
      "[762/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54343, val loss: 0.57518, in 0.019s\n",
      "[763/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54339, val loss: 0.57520, in 0.020s\n",
      "[764/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54333, val loss: 0.57518, in 0.021s\n",
      "[765/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54326, val loss: 0.57513, in 0.021s\n",
      "[766/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.54320, val loss: 0.57513, in 0.021s\n",
      "[767/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54314, val loss: 0.57512, in 0.021s\n",
      "[768/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54308, val loss: 0.57510, in 0.018s\n",
      "[769/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54304, val loss: 0.57509, in 0.020s\n",
      "[770/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54300, val loss: 0.57509, in 0.018s\n",
      "[771/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54294, val loss: 0.57504, in 0.020s\n",
      "[772/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54288, val loss: 0.57500, in 0.019s\n",
      "[773/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54279, val loss: 0.57498, in 0.021s\n",
      "[774/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54274, val loss: 0.57497, in 0.020s\n",
      "[775/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54271, val loss: 0.57498, in 0.017s\n",
      "[776/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54266, val loss: 0.57497, in 0.020s\n",
      "[777/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54261, val loss: 0.57498, in 0.019s\n",
      "[778/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54254, val loss: 0.57497, in 0.021s\n",
      "[779/10000] 1 tree, 31 leaves, max depth = 18, train loss: 0.54248, val loss: 0.57495, in 0.021s\n",
      "[780/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54243, val loss: 0.57493, in 0.021s\n",
      "[781/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54237, val loss: 0.57491, in 0.021s\n",
      "[782/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54231, val loss: 0.57488, in 0.022s\n",
      "[783/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54223, val loss: 0.57481, in 0.043s\n",
      "[784/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54218, val loss: 0.57480, in 0.023s\n",
      "[785/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54216, val loss: 0.57479, in 0.018s\n",
      "[786/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54213, val loss: 0.57480, in 0.017s\n",
      "[787/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54210, val loss: 0.57479, in 0.019s\n",
      "[788/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54202, val loss: 0.57476, in 0.020s\n",
      "[789/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54197, val loss: 0.57476, in 0.020s\n",
      "[790/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54191, val loss: 0.57472, in 0.019s\n",
      "[791/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54186, val loss: 0.57472, in 0.018s\n",
      "[792/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54179, val loss: 0.57470, in 0.020s\n",
      "[793/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54173, val loss: 0.57467, in 0.021s\n",
      "[794/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54168, val loss: 0.57466, in 0.021s\n",
      "[795/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54161, val loss: 0.57464, in 0.020s\n",
      "[796/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54158, val loss: 0.57464, in 0.017s\n",
      "[797/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54148, val loss: 0.57457, in 0.021s\n",
      "[798/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54143, val loss: 0.57453, in 0.019s\n",
      "[799/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54136, val loss: 0.57450, in 0.021s\n",
      "[800/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54131, val loss: 0.57449, in 0.018s\n",
      "[801/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54122, val loss: 0.57443, in 0.022s\n",
      "[802/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54119, val loss: 0.57444, in 0.017s\n",
      "[803/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54115, val loss: 0.57444, in 0.018s\n",
      "[804/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54110, val loss: 0.57442, in 0.018s\n",
      "[805/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54105, val loss: 0.57442, in 0.019s\n",
      "[806/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54098, val loss: 0.57439, in 0.025s\n",
      "[807/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54091, val loss: 0.57436, in 0.038s\n",
      "[808/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54088, val loss: 0.57436, in 0.019s\n",
      "[809/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54083, val loss: 0.57436, in 0.018s\n",
      "[810/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54077, val loss: 0.57434, in 0.020s\n",
      "[811/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.54071, val loss: 0.57434, in 0.018s\n",
      "[812/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54065, val loss: 0.57432, in 0.018s\n",
      "[813/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54060, val loss: 0.57431, in 0.017s\n",
      "[814/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54055, val loss: 0.57431, in 0.016s\n",
      "[815/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54052, val loss: 0.57430, in 0.015s\n",
      "[816/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54050, val loss: 0.57430, in 0.015s\n",
      "[817/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54046, val loss: 0.57429, in 0.017s\n",
      "[818/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54040, val loss: 0.57428, in 0.019s\n",
      "[819/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54038, val loss: 0.57429, in 0.016s\n",
      "[820/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54034, val loss: 0.57429, in 0.017s\n",
      "[821/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54031, val loss: 0.57428, in 0.015s\n",
      "[822/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54026, val loss: 0.57428, in 0.018s\n",
      "[823/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54021, val loss: 0.57427, in 0.017s\n",
      "[824/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54019, val loss: 0.57426, in 0.016s\n",
      "[825/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54013, val loss: 0.57425, in 0.017s\n",
      "[826/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54008, val loss: 0.57424, in 0.017s\n",
      "[827/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54004, val loss: 0.57426, in 0.019s\n",
      "[828/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53998, val loss: 0.57424, in 0.017s\n",
      "[829/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53992, val loss: 0.57425, in 0.016s\n",
      "[830/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53986, val loss: 0.57423, in 0.017s\n",
      "[831/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53982, val loss: 0.57424, in 0.016s\n",
      "[832/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53977, val loss: 0.57422, in 0.016s\n",
      "[833/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53971, val loss: 0.57419, in 0.017s\n",
      "[834/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53967, val loss: 0.57418, in 0.017s\n",
      "[835/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53959, val loss: 0.57417, in 0.019s\n",
      "[836/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53955, val loss: 0.57418, in 0.017s\n",
      "[837/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53949, val loss: 0.57417, in 0.018s\n",
      "[838/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53940, val loss: 0.57413, in 0.018s\n",
      "[839/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.53935, val loss: 0.57411, in 0.018s\n",
      "[840/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53929, val loss: 0.57410, in 0.019s\n",
      "[841/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.53927, val loss: 0.57410, in 0.016s\n",
      "[842/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53922, val loss: 0.57410, in 0.017s\n",
      "[843/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53919, val loss: 0.57409, in 0.017s\n",
      "[844/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.53913, val loss: 0.57411, in 0.017s\n",
      "[845/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53907, val loss: 0.57409, in 0.018s\n",
      "[846/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53899, val loss: 0.57404, in 0.017s\n",
      "[847/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53897, val loss: 0.57404, in 0.016s\n",
      "[848/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.53892, val loss: 0.57403, in 0.018s\n",
      "[849/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53885, val loss: 0.57403, in 0.018s\n",
      "[850/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53880, val loss: 0.57402, in 0.017s\n",
      "[851/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53873, val loss: 0.57400, in 0.017s\n",
      "[852/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53868, val loss: 0.57398, in 0.038s\n",
      "[853/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53861, val loss: 0.57399, in 0.026s\n",
      "[854/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53856, val loss: 0.57399, in 0.018s\n",
      "[855/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53850, val loss: 0.57396, in 0.019s\n",
      "[856/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53847, val loss: 0.57396, in 0.015s\n",
      "[857/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.53840, val loss: 0.57394, in 0.019s\n",
      "[858/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.53837, val loss: 0.57393, in 0.017s\n",
      "[859/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53833, val loss: 0.57393, in 0.016s\n",
      "[860/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53831, val loss: 0.57392, in 0.018s\n",
      "[861/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53824, val loss: 0.57389, in 0.021s\n",
      "[862/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53820, val loss: 0.57390, in 0.028s\n",
      "[863/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.53814, val loss: 0.57389, in 0.019s\n",
      "[864/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.53810, val loss: 0.57389, in 0.017s\n",
      "[865/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53804, val loss: 0.57390, in 0.020s\n",
      "[866/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53800, val loss: 0.57389, in 0.019s\n",
      "[867/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.53795, val loss: 0.57387, in 0.017s\n",
      "[868/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53791, val loss: 0.57388, in 0.018s\n",
      "[869/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.53785, val loss: 0.57389, in 0.019s\n",
      "[870/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.53779, val loss: 0.57388, in 0.020s\n",
      "[871/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53771, val loss: 0.57383, in 0.023s\n",
      "[872/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.53766, val loss: 0.57383, in 0.019s\n",
      "[873/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.53761, val loss: 0.57386, in 0.017s\n",
      "[874/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.53758, val loss: 0.57387, in 0.017s\n",
      "[875/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53751, val loss: 0.57386, in 0.023s\n",
      "[876/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53747, val loss: 0.57387, in 0.018s\n",
      "[877/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53742, val loss: 0.57387, in 0.018s\n",
      "[878/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53735, val loss: 0.57381, in 0.019s\n",
      "[879/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53728, val loss: 0.57378, in 0.020s\n",
      "[880/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53724, val loss: 0.57378, in 0.020s\n",
      "[881/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.53718, val loss: 0.57376, in 0.018s\n",
      "[882/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53714, val loss: 0.57376, in 0.018s\n",
      "[883/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.53709, val loss: 0.57375, in 0.018s\n",
      "[884/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.53704, val loss: 0.57372, in 0.024s\n",
      "[885/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53697, val loss: 0.57368, in 0.021s\n",
      "[886/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.53693, val loss: 0.57370, in 0.031s\n",
      "[887/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53688, val loss: 0.57369, in 0.022s\n",
      "[888/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53685, val loss: 0.57371, in 0.020s\n",
      "[889/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.53681, val loss: 0.57372, in 0.018s\n",
      "[890/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.53677, val loss: 0.57371, in 0.019s\n",
      "[891/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53671, val loss: 0.57369, in 0.021s\n",
      "[892/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.53667, val loss: 0.57371, in 0.019s\n",
      "[893/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.53662, val loss: 0.57369, in 0.018s\n",
      "[894/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.53660, val loss: 0.57369, in 0.018s\n",
      "[895/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.53657, val loss: 0.57370, in 0.019s\n",
      "Fit 895 trees in 18.864 s, (27745 total leaves)\n",
      "Time spent computing histograms: 6.741s\n",
      "Time spent finding best splits:  1.017s\n",
      "Time spent applying splits:      1.850s\n",
      "Time spent predicting:           0.380s\n",
      "Accuracy Score: 0.7009613417876867\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.73      0.71     51335\n",
      "         1.0       0.71      0.67      0.69     51334\n",
      "\n",
      "    accuracy                           0.70    102669\n",
      "   macro avg       0.70      0.70      0.70    102669\n",
      "weighted avg       0.70      0.70      0.70    102669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# Instantiate the model with default hyperparameters\n",
    "gbc = HistGradientBoostingClassifier(max_iter = 10000, verbose=1, random_state=0)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
