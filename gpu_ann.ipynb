{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "LR=0.01\n",
    "EPOCHS=10\n",
    "TRAIN_BATCH=256\n",
    "TEST_BATCH=1024\n",
    "\n",
    "NUM_CLASSES=2\n",
    "\n",
    "NUM_WORKERS=0\n",
    "PIN_MEMORY=True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self,in_features,num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(in_features=in_features,out_features=256)\n",
    "        self.fc2=nn.Linear(in_features=256,out_features=num_classes)\n",
    "    def forward(self,x):\n",
    "        pred=F.relu(self.fc1(x))\n",
    "        pred=self.fc2(pred)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,data,labels):\n",
    "        self.data=data\n",
    "        self.labels=labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self,index):\n",
    "        return self.data[index].toarray()[0],self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, criterion):\n",
    "    model=model.train()\n",
    "    losses = []\n",
    "    correct=0\n",
    "    incorrect=0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        correct += torch.sum(output.argmax(axis=1) == target)\n",
    "        incorrect += torch.sum(output.argmax(axis=1) != target)\n",
    "    return np.mean(losses), (100.0 * correct / (correct+incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_res(res,output,target):\n",
    "    for i in range(target.shape[0]):\n",
    "        if(output[i]==target[i]==1):\n",
    "            res[\"tp\"]+=1\n",
    "        elif(output[i]!=target[i] and target[i]==1):\n",
    "            res[\"fn\"]+=1\n",
    "        elif(output[i]==target[i]==0):\n",
    "            res[\"tn\"]+=1\n",
    "        else:\n",
    "            res[\"fp\"]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion):\n",
    "    model=model.eval()\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    incorrect=0\n",
    "    res={\"fp\":0,\"tp\":0,\"fn\":0,\"tn\":0}\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            losses.append(criterion(output, target).item())\n",
    "            update_res(res,output.argmax(axis=1),target)\n",
    "            correct += torch.sum(output.argmax(axis=1) == target)\n",
    "            incorrect += torch.sum(output.argmax(axis=1) != target)\n",
    "    return np.mean(losses), (100.0 * correct / (correct+incorrect)), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    features,labels=utils.preproc_data(*utils.load_data())\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=4)\n",
    "    train_loader=torch.utils.data.DataLoader(\n",
    "        SparseDataset(x_train,y_train),\n",
    "        batch_size=TRAIN_BATCH,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    test_loader=torch.utils.data.DataLoader(\n",
    "        SparseDataset(x_test,y_test),\n",
    "        batch_size=TEST_BATCH,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    return train_loader, test_loader, features.shape[1], NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_losses(train_losses,test_losses):\n",
    "    plt.figure()\n",
    "    plt.plot(range(EPOCHS),train_losses, label=\"Train Loss\")\n",
    "    plt.plot(range(EPOCHS),test_losses, label=\"Test Loss\")\n",
    "    plt.title('Train and Test Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_loader,test_loader,in_features,num_classes=load_data()\n",
    "    model=ANN(in_features=in_features,num_classes=num_classes)\n",
    "    model=model.to(device)\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer=optim.SGD(model.parameters(),lr=LR)\n",
    "    train_losses=[]\n",
    "    test_losses=[]\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss,train_acc=train(train_loader,model,optimizer,criterion)\n",
    "        train_losses.append(train_loss)\n",
    "        test_loss,test_acc,test_res=test(test_loader,model,criterion)\n",
    "        test_losses.append(test_loss)\n",
    "        print(f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss}')\n",
    "    plt_losses(train_losses,test_losses)\n",
    "    print(f'Accuracy: {test_acc}')\n",
    "    print(f'fp: {test_res[\"fp\"]}, tp: {test_res[\"tp\"]}, fn: {test_res[\"fn\"]}, tn: {test_res[\"tn\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
